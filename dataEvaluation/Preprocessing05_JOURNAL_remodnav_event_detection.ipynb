{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing 05 - event detection\n",
    "\n",
    "## Import Libraries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dataEvaluation.utils.remodnav import perform_remodnav\n",
    "import scipy.signal as signal\n",
    "import os\n",
    "import contextlib\n",
    "from tqdm.notebook import tqdm\n",
    "import scipy.ndimage as ndimage"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Eyetracking Event Detection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def count_nan_beginning(data):\n",
    "    count = 0\n",
    "    for value in data:\n",
    "        if np.isnan(value):\n",
    "            count += 1\n",
    "        else:\n",
    "            return count\n",
    "    return count\n",
    "\n",
    "def count_nan_end(data):\n",
    "    count = 0\n",
    "    for value in data[::-1]:\n",
    "        if np.isnan(value):\n",
    "            count += 1\n",
    "        else:\n",
    "            return count\n",
    "    return count\n",
    "\n",
    "# get where values are nan\n",
    "\n",
    "def get_coherent_nan(series):\n",
    "    nan_idx = np.where(np.isnan(series))[0]\n",
    "    coherent_nans = []\n",
    "    current_start = None\n",
    "    last_value = None\n",
    "    for current_value in nan_idx:\n",
    "        if current_start is None:\n",
    "            current_start = current_value\n",
    "        elif abs(current_value - last_value) != 1:\n",
    "            coherent_nans.append((current_start, last_value))\n",
    "            current_start = current_value\n",
    "        last_value = current_value\n",
    "    if current_start is not None:\n",
    "        coherent_nans.append((current_start, last_value))\n",
    "    return coherent_nans\n",
    "\n",
    "def get_coherent_non_nan(series):\n",
    "    non_nan_idx = np.where(np.logical_not(np.isnan(series)))[0]\n",
    "    coherent_non_nans = []\n",
    "    current_start = None\n",
    "    last_value = None\n",
    "    for current_value in non_nan_idx:\n",
    "        if current_start is None:\n",
    "            current_start = current_value\n",
    "        elif abs(current_value - last_value) != 1:\n",
    "            coherent_non_nans.append((current_start, last_value))\n",
    "            current_start = current_value\n",
    "        last_value = current_value\n",
    "    if current_start is not None:\n",
    "        coherent_non_nans.append((current_start, last_value))\n",
    "    return coherent_non_nans\n",
    "\n",
    "def interpolate_by_nearest(x, y, max_error_duration=0.1, sampling_rate = 250):\n",
    "    x = x.copy()\n",
    "    y = y.copy()\n",
    "\n",
    "    duration_per_step = 1.0/sampling_rate\n",
    "    max_number_of_steps = int(max_error_duration/duration_per_step)\n",
    "\n",
    "    # eliminate single nan values\n",
    "    changed = True\n",
    "    while changed:\n",
    "        changed = False\n",
    "\n",
    "        x_ranges = [(idx, cur[1]-cur[0], cur) for idx, cur in enumerate(get_coherent_nan(x))]\n",
    "        y_ranges = [(idx, cur[1]-cur[0], cur) for idx, cur in enumerate(get_coherent_nan(y))]\n",
    "\n",
    "        x_error_indexes = [idx for idx, cur in enumerate(x_ranges) if cur[1] <= max_number_of_steps]\n",
    "        y_error_indexes = [idx for idx, cur in enumerate(y_ranges) if cur[1] <= max_number_of_steps]\n",
    "\n",
    "        # set values to nearest interpolation\n",
    "        for idx in x_error_indexes:\n",
    "            min_idx, max_idx = x_ranges[idx][2]\n",
    "            min_idx = max(0, min_idx-1)\n",
    "            max_idx = min(len(x), max_idx+2)\n",
    "            try:\n",
    "                x[min_idx:max_idx] = pd.Series(x[min_idx:max_idx]).interpolate(method='nearest')\n",
    "                changed = True\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        for idx in y_error_indexes:\n",
    "            min_idx, max_idx = y_ranges[idx][2]\n",
    "            min_idx = max(0, min_idx-1)\n",
    "            max_idx = min(len(y), max_idx+2)\n",
    "            try:\n",
    "                y[min_idx:max_idx] = pd.Series(y[min_idx:max_idx]).interpolate(method='nearest')\n",
    "                changed = True\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    # eliminate single non nan values\n",
    "    changed = True\n",
    "    while changed:\n",
    "        changed = False\n",
    "\n",
    "        x_ranges = [(idx, cur[1]-cur[0], cur) for idx, cur in enumerate(get_coherent_non_nan(x))]\n",
    "        y_ranges = [(idx, cur[1]-cur[0], cur) for idx, cur in enumerate(get_coherent_non_nan(y))]\n",
    "\n",
    "        x_error_indexes = [idx for idx, length, _ in x_ranges if length <= max_number_of_steps]\n",
    "        y_error_indexes = [idx for idx, length, _ in y_ranges if length <= max_number_of_steps]\n",
    "\n",
    "        # remove error_index values and set them to nan\n",
    "        for idx in x_error_indexes:\n",
    "            min_value, max_value = x_ranges[idx][2]\n",
    "            x[min_value:max_value+1] = np.nan\n",
    "            y[min_value:max_value+1] = np.nan\n",
    "            changed = True\n",
    "\n",
    "        for idx in y_error_indexes:\n",
    "            min_value, max_value = y_ranges[idx][2]\n",
    "            x[min_value:max_value+1] = np.nan\n",
    "            y[min_value:max_value+1] = np.nan\n",
    "            changed = True\n",
    "\n",
    "    nan_x_ranges = [(idx, cur[1]-cur[0], cur) for idx, cur in enumerate(get_coherent_nan(x))]\n",
    "    nan_y_ranges = [(idx, cur[1]-cur[0], cur) for idx, cur in enumerate(get_coherent_nan(y))]\n",
    "\n",
    "    try:\n",
    "        nan_x_values = np.where(np.isnan(x))[0]\n",
    "        inter_x_values = x.interpolate(method='pad')\n",
    "        inter_x_values_filter = ndimage.gaussian_filter1d(inter_x_values, sigma=1.0)\n",
    "        inter_x_values[nan_x_values] = inter_x_values_filter[nan_x_values]\n",
    "    except:\n",
    "        inter_x_values = x\n",
    "\n",
    "    try:\n",
    "        nan_y_values = np.where(np.isnan(y))[0]\n",
    "        inter_y_values = y.interpolate(method='pad')\n",
    "        inter_y_values_filter = ndimage.gaussian_filter1d(inter_y_values, sigma=1.0)\n",
    "        inter_y_values[nan_y_values] = inter_y_values_filter[nan_y_values]\n",
    "    except:\n",
    "        inter_y_values = y\n",
    "\n",
    "    return inter_x_values, inter_y_values, [data[2] for data in nan_x_ranges], [data[2] for data in nan_y_ranges]\n",
    "\n",
    "def get_matching_nans(x_nan, y_nan, length):\n",
    "    data_x = np.zeros(length, dtype=bool)\n",
    "    data_y = np.zeros(length, dtype=bool)\n",
    "    for low, high in x_nan:\n",
    "        data_x[low:high+1] = True\n",
    "    for low, high in y_nan:\n",
    "        data_y[low:high+1] = True\n",
    "    data_mask = np.logical_and(data_x, data_y)\n",
    "    data = np.zeros(length)\n",
    "    data[data_mask] = np.nan\n",
    "    return get_coherent_nan(data)\n",
    "\n",
    "def remove_interpolated_events(df):\n",
    "    df_blink = df[df[\"label\"] == \"PBlink\"]\n",
    "    df[\"Keep\"] = True\n",
    "    for idx, row in df.iterrows():\n",
    "        if row[\"label\"] == \"PBlink\":\n",
    "            continue\n",
    "        start_time = row[\"start_time\"]\n",
    "        end_time = row[\"end_time\"]\n",
    "        for blink_idx, blink_row in df_blink.iterrows():\n",
    "            blink_start_time = blink_row[\"start_time\"]\n",
    "            blink_end_time = blink_row[\"end_time\"]\n",
    "            if blink_start_time <= start_time <= blink_end_time:\n",
    "                df.loc[idx, \"Keep\"] = False\n",
    "                break\n",
    "            if blink_start_time <= end_time <= blink_end_time:\n",
    "                df.loc[idx, \"Keep\"] = False\n",
    "                break\n",
    "            if start_time <= blink_start_time <= end_time:\n",
    "                df.loc[idx, \"Keep\"] = False\n",
    "                break\n",
    "            if start_time <= blink_end_time <= end_time:\n",
    "                df.loc[idx, \"Keep\"] = False\n",
    "                break\n",
    "    df = df[df[\"Keep\"] == True]\n",
    "    df = df.drop(columns=[\"Keep\"])\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/3270 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7e381c6c397b4f1cbf9f1ffec2782808"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read in the Behavioral Data\n",
    "df_behavioral = pd.read_csv(\"./data/filteredData/filtered_data.csv\")\n",
    "\n",
    "sampling_rate = 250.0\n",
    "max_error_duration = 0.1\n",
    "screen_resolution = (1920, 1080)\n",
    "screen_size = (56.0, 31.5)\n",
    "screen_distance = 60.0\n",
    "x_res = 1920.0\n",
    "y_res = 1080.0\n",
    "\n",
    "df_events = pd.DataFrame(columns=[\"Participant\", \"Algorithm\", \"Subpart\",\n",
    "                                  \"id\", \"label\", \"start_x\", \"start_y\", \"end_x\", \"end_y\", \"start_time\", \"end_time\",\n",
    "                                  \"amp\", \"peak_vel\", \"med_vel\", \"avg_vel\"])\n",
    "errors = []\n",
    "\n",
    "for index, row in tqdm(df_behavioral.iterrows(), total=len(df_behavioral)):\n",
    "    # read in eyetracking file\n",
    "    df_eyetracking = pd.read_csv(row[\"Eyetracking\"])\n",
    "    participant = row[\"Participant\"]\n",
    "    algorithm = row[\"Algorithm\"]\n",
    "    subpart = row[\"Subpart\"]\n",
    "\n",
    "    # normalize the time regarding eyetracking to 0\n",
    "    df_eyetracking[\"time\"] = df_eyetracking[\"time\"].astype(float)\n",
    "    df_eyetracking[\"time\"] = df_eyetracking[\"time\"] - df_eyetracking[\"time\"].iloc[0]\n",
    "\n",
    "    # drop unused columns\n",
    "    df_eyetracking = df_eyetracking.drop(columns=[\"l_gaze_point_in_user_coordinate_system_x\",\n",
    "                                                  \"l_gaze_point_in_user_coordinate_system_y\",\n",
    "                                                  \"l_gaze_point_in_user_coordinate_system_z\",\n",
    "                                                  \"r_gaze_point_in_user_coordinate_system_x\",\n",
    "                                                  \"r_gaze_point_in_user_coordinate_system_y\",\n",
    "                                                  \"r_gaze_point_in_user_coordinate_system_z\",\n",
    "                                                  \"l_gaze_origin_in_user_coordinate_system_x\",\n",
    "                                                  \"l_gaze_origin_in_user_coordinate_system_y\",\n",
    "                                                  \"l_gaze_origin_in_user_coordinate_system_z\",\n",
    "                                                  \"r_gaze_origin_in_user_coordinate_system_x\",\n",
    "                                                  \"r_gaze_origin_in_user_coordinate_system_y\",\n",
    "                                                  \"r_gaze_origin_in_user_coordinate_system_z\"])\n",
    "\n",
    "    # convert eyetracking data to display coordinates\n",
    "    df_eyetracking[\"l_display_x\"] = df_eyetracking[\"l_display_x\"].astype(float) * x_res\n",
    "    df_eyetracking[\"l_display_y\"] = df_eyetracking[\"l_display_y\"].astype(float) * y_res\n",
    "    df_eyetracking[\"r_display_x\"] = df_eyetracking[\"r_display_x\"].astype(float) * x_res\n",
    "    df_eyetracking[\"r_display_y\"] = df_eyetracking[\"r_display_y\"].astype(float) * y_res\n",
    "\n",
    "    # convert eyetracking data to I2MC valid flags\n",
    "    df_eyetracking[\"l_valid\"] = df_eyetracking[\"l_valid\"].astype(int)\n",
    "    df_eyetracking[\"r_valid\"] = df_eyetracking[\"r_valid\"].astype(int)\n",
    "\n",
    "    # convert miss column to right integer used by I2MC\n",
    "    df_eyetracking[\"l_miss_x\"] = df_eyetracking.apply(lambda row: row[\"l_display_x\"] < -x_res or row[\"l_display_x\"] > 2 * x_res, axis=1)\n",
    "    df_eyetracking[\"l_miss_y\"] = df_eyetracking.apply(lambda row: row[\"l_display_y\"] < -y_res or row[\"l_display_y\"] > 2 * y_res, axis=1)\n",
    "    df_eyetracking[\"r_miss_x\"] = df_eyetracking.apply(lambda row: row[\"r_display_x\"] < -x_res or row[\"r_display_x\"] > 2 * x_res, axis=1)\n",
    "    df_eyetracking[\"r_miss_y\"] = df_eyetracking.apply(lambda row: row[\"r_display_y\"] < -y_res or row[\"r_display_y\"] > 2 * y_res, axis=1)\n",
    "\n",
    "    df_eyetracking[\"l_miss\"] = df_eyetracking.apply(lambda row: row[\"l_miss_x\"] or row[\"l_miss_y\"] or not row[\"l_valid\"] >= 1, axis=1)\n",
    "    df_eyetracking[\"r_miss\"] = df_eyetracking.apply(lambda row: row[\"r_miss_x\"] or row[\"r_miss_y\"] or not row[\"r_valid\"] >= 1, axis=1)\n",
    "\n",
    "    # Set a default value for missing data\n",
    "    df_eyetracking.loc[df_eyetracking[\"l_miss\"], \"l_display_x\"] = np.nan\n",
    "    df_eyetracking.loc[df_eyetracking[\"l_miss\"], \"l_display_y\"] = np.nan\n",
    "    df_eyetracking.loc[df_eyetracking[\"r_miss\"], \"r_display_x\"] = np.nan\n",
    "    df_eyetracking.loc[df_eyetracking[\"r_miss\"], \"r_display_y\"] = np.nan\n",
    "\n",
    "\n",
    "    # check where l_display_x and l_display_y are NaN\n",
    "    # interpolate missing data and store nans\n",
    "    l_display_x, l_display_y, l_x_nan, l_y_nan = interpolate_by_nearest(\n",
    "        df_eyetracking['l_display_x'], df_eyetracking['l_display_y'],\n",
    "        max_error_duration, sampling_rate)\n",
    "    r_display_x, r_display_y, r_x_nan, r_y_nan = interpolate_by_nearest(\n",
    "        df_eyetracking['r_display_x'], df_eyetracking['r_display_y'],\n",
    "        max_error_duration, sampling_rate)\n",
    "    l_nan = get_matching_nans(l_x_nan, l_y_nan, len(df_eyetracking))\n",
    "    r_nan = get_matching_nans(r_x_nan, r_y_nan, len(df_eyetracking))\n",
    "    a_nan = get_matching_nans(l_nan, r_nan, len(df_eyetracking))\n",
    "    a_nan = [(start/sampling_rate, end/sampling_rate, (end-start)/sampling_rate) for start, end in a_nan]\n",
    "\n",
    "    with open(os.devnull, 'w') as devnull:\n",
    "        with contextlib.redirect_stdout(devnull):\n",
    "            with contextlib.redirect_stderr(devnull):\n",
    "                # average x of both eyes\n",
    "                avg_x = np.nanmean(np.stack([l_display_x, r_display_x]), axis=0)\n",
    "                # average y of both eyes\n",
    "                avg_y = np.nanmean(np.stack([l_display_y, r_display_y]), axis=0)\n",
    "\n",
    "    # apply moving average filter\n",
    "    avg_x = signal.medfilt(avg_x, kernel_size=7)\n",
    "    avg_y = signal.medfilt(avg_y, kernel_size=7)\n",
    "\n",
    "    nan_beginning = max(count_nan_beginning(avg_x), count_nan_beginning(avg_y))\n",
    "    nan_end = max(count_nan_end(avg_x), count_nan_end(avg_y), 1)\n",
    "\n",
    "    avg_x = avg_x[nan_beginning:-nan_end]\n",
    "    avg_y = avg_y[nan_beginning:-nan_end]\n",
    "\n",
    "    time_offset = 1.0/sampling_rate * nan_beginning\n",
    "\n",
    "    try:\n",
    "        # disallow outputting for next function\n",
    "        with open(os.devnull, 'w') as devnull:\n",
    "            with contextlib.redirect_stdout(devnull):\n",
    "                with contextlib.redirect_stderr(devnull):\n",
    "                    events, pp, clf = perform_remodnav(\n",
    "                        avg_x, avg_y,\n",
    "                        sampling_rate,\n",
    "                        screen_width=screen_size[0],\n",
    "                        screen_width_pixels=screen_resolution[0],\n",
    "                        screen_distance=screen_distance,\n",
    "                        savgol_length=0.02)\n",
    "    except Exception as e:\n",
    "        print(index)\n",
    "        print(e)\n",
    "\n",
    "    df_tmp = pd.DataFrame(columns=df_events.columns)\n",
    "    for cure_idx, value in enumerate(events):\n",
    "        value[\"Participant\"] = participant\n",
    "        value[\"Subpart\"] = subpart\n",
    "        value[\"Algorithm\"] = algorithm\n",
    "        df_tmp.loc[len(df_tmp)] = value\n",
    "\n",
    "    for potential_blink in a_nan:\n",
    "        blink_event = {}\n",
    "        blink_event[\"Participant\"] = participant\n",
    "        blink_event[\"Algorithm\"] = algorithm\n",
    "        blink_event[\"Subpart\"] = subpart\n",
    "        blink_event[\"label\"] = \"PBlink\"\n",
    "        blink_event[\"start_time\"] = potential_blink[0]\n",
    "        blink_event[\"end_time\"] = potential_blink[1]\n",
    "        df_tmp.loc[len(df_tmp)] = blink_event\n",
    "\n",
    "    #df_tmp = remove_interpolated_events(df_tmp)\n",
    "    df_tmp = df_tmp.reset_index(drop=True)\n",
    "    # append the non duplicated rows to the final dataframe\n",
    "    df_events = pd.concat([df_events, df_tmp], ignore_index=True)\n",
    "    df_events = df_events.reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Export The Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/3270 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d1499a74477d4a189f2bfef11a780adb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for (participant, algorithm, subpart), df_group in tqdm(df_events.groupby([\"Participant\", \"Algorithm\", \"Subpart\"])):\n",
    "    df_group = df_group.reset_index(drop=True)\n",
    "    df_group = df_group.sort_values(by=\"start_time\")\n",
    "    # drop columns that are not needed\n",
    "    df_group = df_group.drop(columns=[\"Participant\", \"Algorithm\", \"Subpart\"])\n",
    "    try:\n",
    "        os.remove(f\"./data/filteredData/Participant{str(participant).zfill(2)}/{algorithm}_eyetracking.csv\")\n",
    "    except:\n",
    "        pass\n",
    "    df_group.to_csv(f\"./data/filteredData/Participant{str(participant).zfill(2)}/{algorithm}_{subpart}_eyetracking.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}