{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import utils.GenSnippetsLib as gsl\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import Fixation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def string_to_list_string(data):\n",
    "    data = data.replace(' ', ',')\n",
    "    data = data.replace('\\n', ',')\n",
    "    data = ','.join([element for element in data.split(\",\") if len(element) > 0])\n",
    "    if data[1] == \",\":\n",
    "        data = \"[\" + data[2:]\n",
    "    return data\n",
    "\n",
    "df_fixation = pd.read_csv('./data/filteredData/fixation_stats.csv', sep=\";\")\n",
    "df_fixation = df_fixation[df_fixation[\"IsOutlier\"] == False]\n",
    "df_fixation = df_fixation.drop(columns=[\"IsOutlier\", \"Behavioral\"])\n",
    "df_fixation[\"Fixation_startT\"] = df_fixation[\"Fixation_startT\"].apply(string_to_list_string)\n",
    "df_fixation[\"Fixation_endT\"] = df_fixation[\"Fixation_endT\"].apply(string_to_list_string)\n",
    "df_fixation[\"Fixation_x\"] = df_fixation[\"Fixation_x\"].apply(string_to_list_string)\n",
    "df_fixation[\"Fixation_y\"] = df_fixation[\"Fixation_y\"].apply(string_to_list_string)\n",
    "df_fixation[\"Fixation_x_range\"] = df_fixation[\"Fixation_x_range\"].apply(string_to_list_string)\n",
    "df_fixation[\"Fixation_y_range\"] = df_fixation[\"Fixation_y_range\"].apply(string_to_list_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Token Based Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Read in the Generator for Token Based Metrics to get The BoundingBoxes and Indices of each Token per Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cd2f1d620b624c4e928fd0e574536ef2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "      Algorithm       Token TokenIdx             BoundingBox\n0       IsPrime    Modifier        0    (808, 468, 856, 482)\n1       IsPrime    Modifier        1    (864, 468, 912, 479)\n2       IsPrime   BasicType        2    (920, 469, 976, 479)\n3       IsPrime  Identifier        3   (984, 468, 1040, 479)\n4       IsPrime   Separator        4  (1040, 467, 1048, 481)\n...         ...         ...      ...                     ...\n2700  Rectangle     Keyword       82   (988, 677, 1020, 688)\n2701  Rectangle   Separator       83  (1020, 685, 1028, 688)\n2702  Rectangle  Identifier       84  (1028, 677, 1076, 691)\n2703  Rectangle   Separator       85  (1076, 676, 1100, 691)\n2704  Rectangle   Separator       86    (780, 695, 788, 709)\n\n[2705 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Algorithm</th>\n      <th>Token</th>\n      <th>TokenIdx</th>\n      <th>BoundingBox</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>IsPrime</td>\n      <td>Modifier</td>\n      <td>0</td>\n      <td>(808, 468, 856, 482)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>IsPrime</td>\n      <td>Modifier</td>\n      <td>1</td>\n      <td>(864, 468, 912, 479)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>IsPrime</td>\n      <td>BasicType</td>\n      <td>2</td>\n      <td>(920, 469, 976, 479)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>IsPrime</td>\n      <td>Identifier</td>\n      <td>3</td>\n      <td>(984, 468, 1040, 479)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>IsPrime</td>\n      <td>Separator</td>\n      <td>4</td>\n      <td>(1040, 467, 1048, 481)</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2700</th>\n      <td>Rectangle</td>\n      <td>Keyword</td>\n      <td>82</td>\n      <td>(988, 677, 1020, 688)</td>\n    </tr>\n    <tr>\n      <th>2701</th>\n      <td>Rectangle</td>\n      <td>Separator</td>\n      <td>83</td>\n      <td>(1020, 685, 1028, 688)</td>\n    </tr>\n    <tr>\n      <th>2702</th>\n      <td>Rectangle</td>\n      <td>Identifier</td>\n      <td>84</td>\n      <td>(1028, 677, 1076, 691)</td>\n    </tr>\n    <tr>\n      <th>2703</th>\n      <td>Rectangle</td>\n      <td>Separator</td>\n      <td>85</td>\n      <td>(1076, 676, 1100, 691)</td>\n    </tr>\n    <tr>\n      <th>2704</th>\n      <td>Rectangle</td>\n      <td>Separator</td>\n      <td>86</td>\n      <td>(780, 695, 788, 709)</td>\n    </tr>\n  </tbody>\n</table>\n<p>2705 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Token based AOIs\n",
    "snippets = df_fixation[\"Algorithm\"].unique()\n",
    "df_token_aois = pd.DataFrame(columns=[\"Algorithm\", \"Token\", \"TokenIdx\", \"BoundingBox\"])\n",
    "for snippet in tqdm(snippets):\n",
    "    aoi_token_generator = f\"./../CodeSnippets/aois/Generators/{snippet}_ast.json\"\n",
    "    image, aoi_list = gsl.create_image(aoi_token_generator, font_path=\"./../CodeSnippets/fonts/ttf/\")\n",
    "    height, width = image.size\n",
    "    width_offset = int(1920 * 0.5) - int(height / 2)\n",
    "    height_offset = int(1080 * 0.5) - int(width / 2)\n",
    "    aoi_clustered = []\n",
    "    current_left = None\n",
    "    current_top = None\n",
    "    current_right = None\n",
    "    current_bottom = None\n",
    "    current_aoi = None\n",
    "    color = None\n",
    "    for letter in aoi_list:\n",
    "        if len(letter[\"AOI\"]) == 1 or letter[\"letter\"] == '\\n':\n",
    "            if current_aoi is not None:\n",
    "                aoi_clustered.append(\n",
    "                    (len(aoi_clustered), current_aoi, current_left, current_top, current_right, current_bottom, color))\n",
    "            current_aoi = None\n",
    "            color = None\n",
    "            current_left = None\n",
    "            current_top = None\n",
    "            current_right = None\n",
    "            current_bottom = None\n",
    "            continue\n",
    "        if current_aoi is None:\n",
    "            current_aoi = letter[\"AOI\"][1]\n",
    "            color = letter[\"color\"]\n",
    "            current_left = letter[\"BoundingBox\"][0]\n",
    "            current_top = letter[\"BoundingBox\"][1]\n",
    "            current_right = letter[\"BoundingBox\"][2]\n",
    "            current_bottom = letter[\"BoundingBox\"][3]\n",
    "        elif current_aoi == letter[\"AOI\"][1]:\n",
    "            current_left = min(current_left, letter[\"BoundingBox\"][0])\n",
    "            current_top = min(current_top, letter[\"BoundingBox\"][1])\n",
    "            current_right = max(current_right, letter[\"BoundingBox\"][2])\n",
    "            current_bottom = max(current_bottom, letter[\"BoundingBox\"][3])\n",
    "        else:\n",
    "            aoi_clustered.append(\n",
    "                (len(aoi_clustered), current_aoi, current_left, current_top, current_right, current_bottom, color))\n",
    "            current_aoi = letter[\"AOI\"][1]\n",
    "            color = letter[\"color\"]\n",
    "            current_left = letter[\"BoundingBox\"][0]\n",
    "            current_top = letter[\"BoundingBox\"][1]\n",
    "            current_right = letter[\"BoundingBox\"][2]\n",
    "            current_bottom = letter[\"BoundingBox\"][3]\n",
    "\n",
    "    for token in aoi_clustered:\n",
    "        df_token_aois.loc[len(df_token_aois)] = [snippet, token[1], token[0],\n",
    "                                                 (token[2] + width_offset,\n",
    "                                                  token[3] + height_offset,\n",
    "                                                  token[4] + width_offset,\n",
    "                                                  token[5] + height_offset)]\n",
    "df_token_aois"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Check which Fixation of which Participant is in which Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "09776332e09d4587b7576d0cdb9b46dc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "       Algorithm Participant FixationNumber  FixationDuration TokenIdx\n0        IsPrime           1              4           156.005        0\n1        IsPrime           1              6           292.008        1\n2        IsPrime           1              7           776.019        3\n3        IsPrime           1             11           196.006       13\n4        IsPrime           1             16           480.011       38\n...          ...         ...            ...               ...      ...\n37381  Rectangle          70             70           347.998       66\n37382  Rectangle          71             16           212.006       43\n37383  Rectangle          71             17           776.027       42\n37384  Rectangle          71             26           152.003       42\n37385  Rectangle          71             29           148.004       32\n\n[37386 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Algorithm</th>\n      <th>Participant</th>\n      <th>FixationNumber</th>\n      <th>FixationDuration</th>\n      <th>TokenIdx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>IsPrime</td>\n      <td>1</td>\n      <td>4</td>\n      <td>156.005</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>IsPrime</td>\n      <td>1</td>\n      <td>6</td>\n      <td>292.008</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>IsPrime</td>\n      <td>1</td>\n      <td>7</td>\n      <td>776.019</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>IsPrime</td>\n      <td>1</td>\n      <td>11</td>\n      <td>196.006</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>IsPrime</td>\n      <td>1</td>\n      <td>16</td>\n      <td>480.011</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>37381</th>\n      <td>Rectangle</td>\n      <td>70</td>\n      <td>70</td>\n      <td>347.998</td>\n      <td>66</td>\n    </tr>\n    <tr>\n      <th>37382</th>\n      <td>Rectangle</td>\n      <td>71</td>\n      <td>16</td>\n      <td>212.006</td>\n      <td>43</td>\n    </tr>\n    <tr>\n      <th>37383</th>\n      <td>Rectangle</td>\n      <td>71</td>\n      <td>17</td>\n      <td>776.027</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>37384</th>\n      <td>Rectangle</td>\n      <td>71</td>\n      <td>26</td>\n      <td>152.003</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>37385</th>\n      <td>Rectangle</td>\n      <td>71</td>\n      <td>29</td>\n      <td>148.004</td>\n      <td>32</td>\n    </tr>\n  </tbody>\n</table>\n<p>37386 rows Ã— 5 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_token_fixation_per_participant = pd.DataFrame([], columns=[\"Algorithm\", \"Participant\", \"FixationNumber\",\n",
    "                                                              \"FixationDuration\", \"TokenIdx\"])\n",
    "participants = df_fixation[\"Participant\"].unique()\n",
    "for snippet in tqdm(snippets):\n",
    "    df_token_per_algo = df_token_aois[df_token_aois[\"Algorithm\"] == snippet]\n",
    "\n",
    "    for participant in participants:\n",
    "        df_fixation_participant = df_fixation[\n",
    "            (df_fixation[\"Algorithm\"] == snippet) & (df_fixation[\"Participant\"] == participant)]\n",
    "        if len(df_fixation_participant) == 0:\n",
    "            continue\n",
    "        start_times = eval(df_fixation_participant[\"Fixation_startT\"].values[0])\n",
    "        end_times = eval(df_fixation_participant[\"Fixation_endT\"].values[0])\n",
    "        x_coordinates = eval(df_fixation_participant[\"Fixation_x\"].values[0])\n",
    "        y_coordinates = eval(df_fixation_participant[\"Fixation_y\"].values[0])\n",
    "        x_range = eval(df_fixation_participant[\"Fixation_x_range\"].values[0])\n",
    "        y_range = eval(df_fixation_participant[\"Fixation_y_range\"].values[0])\n",
    "        idx_values = range(len(start_times))\n",
    "        for (fix_idx, start, end, x, y, x_range, y_range) in zip(idx_values, start_times, end_times, x_coordinates, y_coordinates, x_range, y_range):\n",
    "            low_x = int(float(x) - math.ceil(float(x_range)))\n",
    "            low_y = int(float(y) - math.ceil(float(y_range)))\n",
    "            high_x = int(float(x) + math.ceil(float(x_range)))\n",
    "            high_y = int(float(y) + math.ceil(float(y_range)))\n",
    "            possible_coordinates = [(x, y) for x in range(low_x, high_x + 1) for y in range(low_y, high_y + 1)]\n",
    "\n",
    "            found = False\n",
    "            for idx, row in df_token_per_algo.iterrows():\n",
    "                token_idx = row[\"TokenIdx\"]\n",
    "                bounding_box = row[\"BoundingBox\"]\n",
    "\n",
    "                for possible_x, possible_y in possible_coordinates:\n",
    "                    if bounding_box[0] <= possible_x <= bounding_box[2] and bounding_box[1] <= possible_y <=bounding_box[3]:\n",
    "                        df_token_fixation_per_participant.loc[len(df_token_fixation_per_participant)] = [snippet, participant,fix_idx,end - start,token_idx]\n",
    "                        found = True\n",
    "                        break\n",
    "                if found:\n",
    "                    break\n",
    "\n",
    "df_token_fixation_per_participant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Transform the Data to a Fixation/ Refixation split by Participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/37386 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9881fc5318ae43a4b78c70e38c4e519f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "      Algorithm TokenIdx      TokenFixation_P1    TokenReFixation_P1  \\\n0       IsPrime        0  [156.00499999999988]                    []   \n1       IsPrime        1   [292.0079999999998]                    []   \n2       IsPrime        2                    []                    []   \n3       IsPrime        3   [776.0190000000002]  [204.00900000000001]   \n4       IsPrime        4                    []                    []   \n...         ...      ...                   ...                   ...   \n2700  Rectangle       82   [376.0139999999992]                    []   \n2701  Rectangle       83                    []                    []   \n2702  Rectangle       84                    []                    []   \n2703  Rectangle       85                    []                    []   \n2704  Rectangle       86                    []                    []   \n\n          TokenFixation_P2                                 TokenReFixation_P2  \\\n0     [296.01099999999997]                                [156.0050000000001]   \n1     [388.01199999999994]              [360.0160000000001, 96.0029999999997]   \n2     [192.01600000000008]  [212.0050000000001, 176.00800000000027, 996.04...   \n3                       []                                                 []   \n4     [236.00099999999998]                                                 []   \n...                    ...                                                ...   \n2700                    []                                                 []   \n2701                    []                                                 []   \n2702                    []                                                 []   \n2703                    []                                                 []   \n2704                    []                                                 []   \n\n          TokenFixation_P3 TokenReFixation_P3     TokenFixation_P4  \\\n0                       []                 []                   []   \n1     [216.00700000000143]                 []  [208.0069999999996]   \n2                       []                 []  [440.0110000000004]   \n3                       []                 []  [620.0229999999997]   \n4                       []                 []                   []   \n...                    ...                ...                  ...   \n2700                    []                 []                   []   \n2701                    []                 []                   []   \n2702                    []                 []                   []   \n2703                    []                 []                   []   \n2704                    []                 []                   []   \n\n     TokenReFixation_P4  ...     TokenFixation_P66 TokenReFixation_P66  \\\n0                    []  ...                    []                  []   \n1                    []  ...                    []                  []   \n2                    []  ...                    []                  []   \n3                    []  ...  [156.00400000000081]  [500.012999999999]   \n4                    []  ...                    []                  []   \n...                 ...  ...                   ...                 ...   \n2700                 []  ...                    []                  []   \n2701                 []  ...                    []                  []   \n2702                 []  ...                    []                  []   \n2703                 []  ...                    []                  []   \n2704                 []  ...                    []                  []   \n\n         TokenFixation_P67                                TokenReFixation_P67  \\\n0      [312.0119999999988]                                                 []   \n1     [1108.0370000000003]  [1240.0420000000013, 232.00499999999738, 648.0...   \n2     [1944.0699999999997]            [235.9960000000001, 3036.1009999999987]   \n3                [740.028]  [900.031, 276.0159999999996, 212.0099999999984...   \n4                       []                                                 []   \n...                    ...                                                ...   \n2700                    []                                                 []   \n2701                    []                                                 []   \n2702                    []                                                 []   \n2703                    []                                                 []   \n2704                    []                                                 []   \n\n        TokenFixation_P68                                TokenReFixation_P68  \\\n0                      []                                                 []   \n1                      []                                                 []   \n2     [704.0219999999999]  [236.00700000000143, 368.01300000000265, 3268....   \n3     [320.0129999999999]                                                 []   \n4                      []                                                 []   \n...                   ...                                                ...   \n2700                   []                                                 []   \n2701                   []                                                 []   \n2702                   []                                                 []   \n2703                   []                                                 []   \n2704                   []                                                 []   \n\n     TokenFixation_P70 TokenReFixation_P70 TokenFixation_P71  \\\n0                   []                  []                []   \n1                   []                  []                []   \n2                   []                  []                []   \n3                   []                  []                []   \n4                   []                  []                []   \n...                ...                 ...               ...   \n2700                []                  []                []   \n2701                []                  []                []   \n2702                []                  []                []   \n2703                []                  []                []   \n2704                []                  []                []   \n\n     TokenReFixation_P71  \n0                     []  \n1                     []  \n2                     []  \n3                     []  \n4                     []  \n...                  ...  \n2700                  []  \n2701                  []  \n2702                  []  \n2703                  []  \n2704                  []  \n\n[2705 rows x 76 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Algorithm</th>\n      <th>TokenIdx</th>\n      <th>TokenFixation_P1</th>\n      <th>TokenReFixation_P1</th>\n      <th>TokenFixation_P2</th>\n      <th>TokenReFixation_P2</th>\n      <th>TokenFixation_P3</th>\n      <th>TokenReFixation_P3</th>\n      <th>TokenFixation_P4</th>\n      <th>TokenReFixation_P4</th>\n      <th>...</th>\n      <th>TokenFixation_P66</th>\n      <th>TokenReFixation_P66</th>\n      <th>TokenFixation_P67</th>\n      <th>TokenReFixation_P67</th>\n      <th>TokenFixation_P68</th>\n      <th>TokenReFixation_P68</th>\n      <th>TokenFixation_P70</th>\n      <th>TokenReFixation_P70</th>\n      <th>TokenFixation_P71</th>\n      <th>TokenReFixation_P71</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>IsPrime</td>\n      <td>0</td>\n      <td>[156.00499999999988]</td>\n      <td>[]</td>\n      <td>[296.01099999999997]</td>\n      <td>[156.0050000000001]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>...</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[312.0119999999988]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>IsPrime</td>\n      <td>1</td>\n      <td>[292.0079999999998]</td>\n      <td>[]</td>\n      <td>[388.01199999999994]</td>\n      <td>[360.0160000000001, 96.0029999999997]</td>\n      <td>[216.00700000000143]</td>\n      <td>[]</td>\n      <td>[208.0069999999996]</td>\n      <td>[]</td>\n      <td>...</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[1108.0370000000003]</td>\n      <td>[1240.0420000000013, 232.00499999999738, 648.0...</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>IsPrime</td>\n      <td>2</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[192.01600000000008]</td>\n      <td>[212.0050000000001, 176.00800000000027, 996.04...</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[440.0110000000004]</td>\n      <td>[]</td>\n      <td>...</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[1944.0699999999997]</td>\n      <td>[235.9960000000001, 3036.1009999999987]</td>\n      <td>[704.0219999999999]</td>\n      <td>[236.00700000000143, 368.01300000000265, 3268....</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>IsPrime</td>\n      <td>3</td>\n      <td>[776.0190000000002]</td>\n      <td>[204.00900000000001]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[620.0229999999997]</td>\n      <td>[]</td>\n      <td>...</td>\n      <td>[156.00400000000081]</td>\n      <td>[500.012999999999]</td>\n      <td>[740.028]</td>\n      <td>[900.031, 276.0159999999996, 212.0099999999984...</td>\n      <td>[320.0129999999999]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>IsPrime</td>\n      <td>4</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[236.00099999999998]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>...</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2700</th>\n      <td>Rectangle</td>\n      <td>82</td>\n      <td>[376.0139999999992]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>...</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>2701</th>\n      <td>Rectangle</td>\n      <td>83</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>...</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>2702</th>\n      <td>Rectangle</td>\n      <td>84</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>...</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>2703</th>\n      <td>Rectangle</td>\n      <td>85</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>...</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>2704</th>\n      <td>Rectangle</td>\n      <td>86</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>...</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n    </tr>\n  </tbody>\n</table>\n<p>2705 rows Ã— 76 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_token = df_token_aois.copy()\n",
    "df_token = df_token.drop([\"BoundingBox\", \"Token\"], axis=1)\n",
    "for participant in participants:\n",
    "    df_token.loc[:, f\"TokenFixation_P{participant}\"] = [[] for _ in range(len(df_token))]\n",
    "    df_token.loc[:, f\"TokenReFixation_P{participant}\"] = [[] for _ in range(len(df_token))]\n",
    "\n",
    "\n",
    "prev_participant = df_token_fixation_per_participant[\"Participant\"].iloc[0]\n",
    "prev_token_idx = df_token_fixation_per_participant[\"TokenIdx\"].iloc[0]\n",
    "prev_algorithm = df_token_fixation_per_participant[\"Algorithm\"].iloc[0]\n",
    "fixations = []\n",
    "re_fixation = False\n",
    "for idx, row in tqdm(df_token_fixation_per_participant.iterrows(), total=len(df_token_fixation_per_participant)):\n",
    "    participant = row[\"Participant\"]\n",
    "    token_idx = row[\"TokenIdx\"]\n",
    "    algorithm = row[\"Algorithm\"]\n",
    "    FixationDuration = row[\"FixationDuration\"]\n",
    "\n",
    "    # fixation switches\n",
    "    if prev_participant != participant or prev_token_idx != token_idx:\n",
    "        index = df_token[(df_token[\"TokenIdx\"] == prev_token_idx) & (df_token[\"Algorithm\"] == prev_algorithm)].index[0]\n",
    "        if re_fixation:\n",
    "            re_fixations = df_token.loc[index, f\"TokenReFixation_P{prev_participant}\"]\n",
    "            re_fixations.extend(fixations.copy())\n",
    "            df_token.loc[index, f\"TokenReFixation_P{prev_participant}\"] = re_fixations.copy()\n",
    "        else:\n",
    "            df_token.loc[index, f\"TokenFixation_P{prev_participant}\"] = fixations.copy()\n",
    "        fixations = []\n",
    "        # possible new fixation\n",
    "        re_fixation = False\n",
    "\n",
    "    sub_frame = df_token[(df_token[\"TokenIdx\"] == token_idx) & (df_token[\"Algorithm\"] == algorithm)]\n",
    "    if len(sub_frame) == 0:\n",
    "        raise Exception(f\"No Token found for {token_idx} in Algorithm {algorithm}\")\n",
    "    len_of_fixation = len(sub_frame[f\"TokenFixation_P{participant}\"].iloc[0])\n",
    "    if re_fixation == False and len_of_fixation > 0 and len(fixations) == 0:\n",
    "        re_fixation = True\n",
    "\n",
    "    fixations.append(FixationDuration)\n",
    "    prev_participant = participant\n",
    "    prev_token_idx = token_idx\n",
    "    prev_algorithm = algorithm\n",
    "\n",
    "df_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Calculate the Token Based Eyetracking Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                  FirstFixationDuration  \\\nFirstFixationDuration                          1.000000   \nSingleFixationDuration                         0.995258   \nGazeDuration                                   0.970602   \nTotalTime                                      0.822191   \nTokenNoFixationProbability                     0.122333   \nTokenSingleFixationProbability                 0.117117   \nTokenMultipleFixationProbability              -0.070175   \nTokenFixationProbability                       0.083452   \nSkill                                         -0.141299   \n\n                                  SingleFixationDuration  GazeDuration  \\\nFirstFixationDuration                           0.995258      0.970602   \nSingleFixationDuration                          1.000000      0.968468   \nGazeDuration                                    0.968468      1.000000   \nTotalTime                                       0.823850      0.781650   \nTokenNoFixationProbability                      0.130394      0.174964   \nTokenSingleFixationProbability                  0.117591      0.066619   \nTokenMultipleFixationProbability               -0.064011     -0.136795   \nTokenFixationProbability                        0.059033      0.120199   \nSkill                                          -0.143433     -0.188952   \n\n                                  TotalTime  TokenNoFixationProbability  \\\nFirstFixationDuration              0.822191                    0.122333   \nSingleFixationDuration             0.823850                    0.130394   \nGazeDuration                       0.781650                    0.174964   \nTotalTime                          1.000000                   -0.040778   \nTokenNoFixationProbability        -0.040778                    1.000000   \nTokenSingleFixationProbability     0.271930                   -0.740161   \nTokenMultipleFixationProbability   0.287340                   -0.717639   \nTokenFixationProbability           0.307729                   -0.541489   \nSkill                             -0.370792                    0.081555   \n\n                                  TokenSingleFixationProbability  \\\nFirstFixationDuration                                   0.117117   \nSingleFixationDuration                                  0.117591   \nGazeDuration                                            0.066619   \nTotalTime                                               0.271930   \nTokenNoFixationProbability                             -0.740161   \nTokenSingleFixationProbability                          1.000000   \nTokenMultipleFixationProbability                        0.800379   \nTokenFixationProbability                                0.625652   \nSkill                                                  -0.311759   \n\n                                  TokenMultipleFixationProbability  \\\nFirstFixationDuration                                    -0.070175   \nSingleFixationDuration                                   -0.064011   \nGazeDuration                                             -0.136795   \nTotalTime                                                 0.287340   \nTokenNoFixationProbability                               -0.717639   \nTokenSingleFixationProbability                            0.800379   \nTokenMultipleFixationProbability                          1.000000   \nTokenFixationProbability                                  0.646278   \nSkill                                                    -0.374111   \n\n                                  TokenFixationProbability     Skill  \nFirstFixationDuration                             0.083452 -0.141299  \nSingleFixationDuration                            0.059033 -0.143433  \nGazeDuration                                      0.120199 -0.188952  \nTotalTime                                         0.307729 -0.370792  \nTokenNoFixationProbability                       -0.541489  0.081555  \nTokenSingleFixationProbability                    0.625652 -0.311759  \nTokenMultipleFixationProbability                  0.646278 -0.374111  \nTokenFixationProbability                          1.000000 -0.586297  \nSkill                                            -0.586297  1.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FirstFixationDuration</th>\n      <th>SingleFixationDuration</th>\n      <th>GazeDuration</th>\n      <th>TotalTime</th>\n      <th>TokenNoFixationProbability</th>\n      <th>TokenSingleFixationProbability</th>\n      <th>TokenMultipleFixationProbability</th>\n      <th>TokenFixationProbability</th>\n      <th>Skill</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>FirstFixationDuration</th>\n      <td>1.000000</td>\n      <td>0.995258</td>\n      <td>0.970602</td>\n      <td>0.822191</td>\n      <td>0.122333</td>\n      <td>0.117117</td>\n      <td>-0.070175</td>\n      <td>0.083452</td>\n      <td>-0.141299</td>\n    </tr>\n    <tr>\n      <th>SingleFixationDuration</th>\n      <td>0.995258</td>\n      <td>1.000000</td>\n      <td>0.968468</td>\n      <td>0.823850</td>\n      <td>0.130394</td>\n      <td>0.117591</td>\n      <td>-0.064011</td>\n      <td>0.059033</td>\n      <td>-0.143433</td>\n    </tr>\n    <tr>\n      <th>GazeDuration</th>\n      <td>0.970602</td>\n      <td>0.968468</td>\n      <td>1.000000</td>\n      <td>0.781650</td>\n      <td>0.174964</td>\n      <td>0.066619</td>\n      <td>-0.136795</td>\n      <td>0.120199</td>\n      <td>-0.188952</td>\n    </tr>\n    <tr>\n      <th>TotalTime</th>\n      <td>0.822191</td>\n      <td>0.823850</td>\n      <td>0.781650</td>\n      <td>1.000000</td>\n      <td>-0.040778</td>\n      <td>0.271930</td>\n      <td>0.287340</td>\n      <td>0.307729</td>\n      <td>-0.370792</td>\n    </tr>\n    <tr>\n      <th>TokenNoFixationProbability</th>\n      <td>0.122333</td>\n      <td>0.130394</td>\n      <td>0.174964</td>\n      <td>-0.040778</td>\n      <td>1.000000</td>\n      <td>-0.740161</td>\n      <td>-0.717639</td>\n      <td>-0.541489</td>\n      <td>0.081555</td>\n    </tr>\n    <tr>\n      <th>TokenSingleFixationProbability</th>\n      <td>0.117117</td>\n      <td>0.117591</td>\n      <td>0.066619</td>\n      <td>0.271930</td>\n      <td>-0.740161</td>\n      <td>1.000000</td>\n      <td>0.800379</td>\n      <td>0.625652</td>\n      <td>-0.311759</td>\n    </tr>\n    <tr>\n      <th>TokenMultipleFixationProbability</th>\n      <td>-0.070175</td>\n      <td>-0.064011</td>\n      <td>-0.136795</td>\n      <td>0.287340</td>\n      <td>-0.717639</td>\n      <td>0.800379</td>\n      <td>1.000000</td>\n      <td>0.646278</td>\n      <td>-0.374111</td>\n    </tr>\n    <tr>\n      <th>TokenFixationProbability</th>\n      <td>0.083452</td>\n      <td>0.059033</td>\n      <td>0.120199</td>\n      <td>0.307729</td>\n      <td>-0.541489</td>\n      <td>0.625652</td>\n      <td>0.646278</td>\n      <td>1.000000</td>\n      <td>-0.586297</td>\n    </tr>\n    <tr>\n      <th>Skill</th>\n      <td>-0.141299</td>\n      <td>-0.143433</td>\n      <td>-0.188952</td>\n      <td>-0.370792</td>\n      <td>0.081555</td>\n      <td>-0.311759</td>\n      <td>-0.374111</td>\n      <td>-0.586297</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Melt the Dataframe to be thinner so that we have Algorithm TokenIdx and Participant and Keys per Fixation / Refixation\n",
    "df_token_melted = pd.melt(df_token, id_vars=[\"Algorithm\", \"TokenIdx\"], var_name=\"KindOfFixation\", value_name=\"FixationDurations\")\n",
    "\n",
    "# Classify Participant and the Kind and Number of Fixations / Refixations\n",
    "df_token_melted[\"Participant\"] = df_token_melted[\"KindOfFixation\"].apply(lambda x: int(x.split(\"_\")[1][1:]))\n",
    "df_token_melted[\"KindOfFixation\"] = df_token_melted[\"KindOfFixation\"].apply(lambda x: x.split(\"_\")[0])\n",
    "df_token_melted[\"KindOfFixation\"] = df_token_melted[\"KindOfFixation\"].apply(lambda x: \"Fixation\" if x == \"TokenFixation\" else \"ReFixation\")\n",
    "df_token_melted[\"NumberOfFixations\"] = df_token_melted[\"FixationDurations\"].apply(lambda x: len(x))\n",
    "\n",
    "# Get the number of Participants for further calculations\n",
    "number_of_participants = len(participants)\n",
    "\n",
    "# Calculate the First Fixation Duration per Participant per Token\n",
    "df_token_melted[\"FirstFixationDuration\"] = None\n",
    "df_token_melted.loc[df_token_melted[\"KindOfFixation\"] == \"Fixation\" , \"FirstFixationDuration\"] = df_token_melted[\"FixationDurations\"]\\\n",
    "    .apply(lambda x: x[0] if len(x) > 0 else None)\n",
    "\n",
    "# Calculate the Single Fixation Duration per Participant per Token\n",
    "df_token_melted[\"SingleFixationDuration\"] = None\n",
    "df_token_melted.loc[df_token_melted[\"KindOfFixation\"] == \"Fixation\" , \"SingleFixationDuration\"] = df_token_melted[\"FixationDurations\"]\\\n",
    "    .apply(lambda x: x[0] if len(x) == 1 else None)\n",
    "\n",
    "# Calculate the Gaze Duration per Participant per Token\n",
    "df_token_melted[\"GazeDuration\"] = None\n",
    "df_token_melted.loc[df_token_melted[\"KindOfFixation\"] == \"Fixation\" , \"GazeDuration\"] = df_token_melted[\"FixationDurations\"]\\\n",
    "    .apply(lambda x: sum(x) if len(x) > 0 else None)\n",
    "\n",
    "# Calculate the Total Time per Participant per Token\n",
    "df_token_melted_total_time = df_token_melted.groupby([\"Participant\", \"Algorithm\", \"TokenIdx\"])\\\n",
    "    .agg({\"FixationDurations\": lambda x: sum(x.values.sum())})\n",
    "df_token_melted_total_time = df_token_melted_total_time.rename(columns={\"FixationDurations\": \"TotalTime\"})\n",
    "\n",
    "# Merge the Dataframes\n",
    "df_token_melted = pd.merge(df_token_melted, df_token_melted_total_time, on=[\"Participant\", \"Algorithm\", \"TokenIdx\"], how=\"left\")\n",
    "\n",
    "# Cast the Dataframes to the right datatype\n",
    "df_token_melted[\"FirstFixationDuration\"] = df_token_melted[\"FirstFixationDuration\"].astype(float)\n",
    "df_token_melted[\"SingleFixationDuration\"] = df_token_melted[\"SingleFixationDuration\"].astype(float)\n",
    "df_token_melted[\"GazeDuration\"] = df_token_melted[\"GazeDuration\"].astype(float)\n",
    "df_token_melted[\"TotalTime\"] = df_token_melted[\"TotalTime\"].astype(float).replace(0, np.nan)\n",
    "\n",
    "# Read in the Skilllevel\n",
    "df_skill = pd.read_csv(f\"./data/filteredData/filtered_data.csv\")\n",
    "df_skill = df_skill[[\"Participant\", \"SkillScore\"]]\n",
    "df_skill = df_skill.drop_duplicates()\n",
    "\n",
    "# Merge the Dataframes to combine metrics with the Skilllevel\n",
    "df_metrics_skill = pd.merge(df_token_melted, df_skill, on=[\"Participant\"], how=\"left\")\n",
    "\n",
    "# Helper Methods for the Metrics\n",
    "def get_single_fixations(df):\n",
    "    df_fixations = df[df[\"KindOfFixation\"] == \"Fixation\"]\n",
    "    df_refixations = df[df[\"KindOfFixation\"] == \"ReFixation\"]\n",
    "    df_refixations = df_refixations[df_refixations[\"NumberOfFixations\"] > 0]\n",
    "    # remove every entry from df fixations on [\"Algorithm\", \"TokenIdx\"] where there is a refixation6\n",
    "    df_fixations = df_fixations[~df_fixations[\"TokenIdx\"].isin(df_refixations[\"TokenIdx\"].values)]\n",
    "    # remove every entry from df fixations on where Number Of Fixations is not 1\n",
    "    df_fixations = df_fixations[df_fixations[\"NumberOfFixations\"] == 1]\n",
    "    return df_fixations\n",
    "\n",
    "def get_no_fixations(df):\n",
    "    df_fixations = df[df[\"KindOfFixation\"] == \"Fixation\"]\n",
    "    # remove every entry from df fixations on [\"Algorithm\", \"TokenIdx\"] where there is a refixation6\n",
    "    df_fixations = df_fixations[df_fixations[\"NumberOfFixations\"] == 0]\n",
    "    return df_fixations\n",
    "\n",
    "\n",
    "def get_fixations(df):\n",
    "    df_fixations = df[df[\"KindOfFixation\"] == \"Fixation\"]\n",
    "    df_refixations = df[df[\"KindOfFixation\"] == \"ReFixation\"]\n",
    "    df_refixations = df_refixations[df_refixations[\"NumberOfFixations\"] > 0]\n",
    "    # remove every entry from df fixations on [\"Algorithm\", \"TokenIdx\"] where there is a refixation6\n",
    "    df_fixations = df_fixations[~df_fixations[\"TokenIdx\"].isin(df_refixations[\"TokenIdx\"].values)]\n",
    "    # remove every entry from df fixations on where Number Of Fixations is not 1\n",
    "    df_fixations = df_fixations[df_fixations[\"NumberOfFixations\"] > 1]\n",
    "    return df_fixations\n",
    "\n",
    "def get_multiple_fixations(df):\n",
    "    df_fixations = df[df[\"KindOfFixation\"] == \"Fixation\"]\n",
    "    df_refixations = df[df[\"KindOfFixation\"] == \"ReFixation\"]\n",
    "    df_refixations = df_refixations[df_refixations[\"NumberOfFixations\"] > 0]\n",
    "    # remove every entry from df fixations on [\"Algorithm\", \"TokenIdx\"] where there is a refixation6\n",
    "    df_fixations = df_fixations[(df_fixations[\"TokenIdx\"].isin(df_refixations[\"TokenIdx\"].values)) & (df_fixations[\"NumberOfFixations\"] >= 1)]\n",
    "    return df_fixations\n",
    "\n",
    "def get_fixations(df):\n",
    "    df_fixations = df[df[\"KindOfFixation\"] == \"Fixation\"]\n",
    "    # remove every entry from df fixations on where no Fixation is found\n",
    "    df_fixations = df_fixations[df_fixations[\"NumberOfFixations\"] > 1]\n",
    "    return df_fixations\n",
    "\n",
    "\n",
    "\n",
    "# dataframe for number of fixations per participant\n",
    "number_of_fixation_per_algorithm = df_metrics_skill.groupby([\"Participant\", \"Algorithm\"])[\"NumberOfFixations\"].count()\n",
    "number_of_fixation_per_algorithm = number_of_fixation_per_algorithm.reset_index()\n",
    "\n",
    "# dataframe for number of tokens per algorithm\n",
    "number_of_tokens_per_algorithm = df_metrics_skill.groupby([\"Algorithm\"])[\"TokenIdx\"].max()\n",
    "number_of_tokens_per_algorithm = number_of_tokens_per_algorithm.reset_index()\n",
    "\n",
    "# dataframe for number of tokens with no fixation per algorithm per participant\n",
    "df_no_fixation_per_algorithm = df_metrics_skill.groupby([\"Participant\", \"Algorithm\"])\\\n",
    "    .apply(get_no_fixations)\\\n",
    "    .drop([\"Algorithm\"], axis=1)\n",
    "\n",
    "# dataframe for number of tokens with only one fixation per algorithm per participant\n",
    "df_single_fixation_per_algorithm = df_metrics_skill.groupby([\"Participant\", \"Algorithm\"])\\\n",
    "    .apply(get_single_fixations)\\\n",
    "    .drop([\"Algorithm\"], axis=1)\n",
    "\n",
    "# dataframe for number of tokens with more than one fixation per algorithm per participant\n",
    "df_multiple_fixation_per_algorithm = df_metrics_skill.groupby([\"Participant\", \"Algorithm\"])\\\n",
    "    .apply(get_multiple_fixations)\\\n",
    "    .drop([\"Algorithm\"], axis=1)\n",
    "\n",
    "# dataframe for number of tokens with more or equal than one fixation per algorithm per participant\n",
    "df_fixation_per_algorithm = df_metrics_skill.groupby([\"Participant\", \"Algorithm\"])\\\n",
    "    .apply(get_fixations)\\\n",
    "    .drop([\"Algorithm\"], axis=1)\n",
    "\n",
    "# Reformat the dataframes\n",
    "no_fixation_per_algorithm = df_no_fixation_per_algorithm[[\"TokenIdx\"]]\n",
    "no_fixation_per_algorithm = no_fixation_per_algorithm.reset_index().drop([\"level_2\"], axis=1)\n",
    "\n",
    "single_fixation_per_algorithm = df_single_fixation_per_algorithm[[\"TokenIdx\"]]\n",
    "single_fixation_per_algorithm = single_fixation_per_algorithm.reset_index().drop([\"level_2\"], axis=1)\n",
    "\n",
    "multiple_fixation_per_algorithm = df_multiple_fixation_per_algorithm[[\"TokenIdx\"]]\n",
    "multiple_fixation_per_algorithm = multiple_fixation_per_algorithm.reset_index().drop([\"level_2\"], axis=1)\n",
    "\n",
    "fixations_per_algorithm = df_fixation_per_algorithm[[\"TokenIdx\"]]\n",
    "fixations_per_algorithm = fixations_per_algorithm.reset_index().drop([\"level_2\"], axis=1)\n",
    "\n",
    "# Helper Method for Probability Metrics\n",
    "def group_len_divided_by_number(current_df, counting_df):\n",
    "    algorithm = current_df[\"Algorithm\"].iloc[0]\n",
    "    number_of_tokens = counting_df[counting_df[\"Algorithm\"] == algorithm][\"TokenIdx\"].iloc[0]\n",
    "    value = len(current_df) / number_of_tokens\n",
    "    return len(current_df) / (number_of_tokens + 1)\n",
    "\n",
    "# Calculate the Metrics per Participant\n",
    "# Probability of no fixation\n",
    "df_no_fixation_probability = no_fixation_per_algorithm.groupby([\"Participant\", \"Algorithm\"]).apply(lambda df: group_len_divided_by_number(df, number_of_tokens_per_algorithm))\n",
    "df_no_fixation_probability = df_no_fixation_probability.reset_index()\n",
    "\n",
    "# Probability of single fixation\n",
    "df_single_fixation_probability = single_fixation_per_algorithm.groupby([\"Participant\", \"Algorithm\"]).apply(lambda df: group_len_divided_by_number(df, number_of_tokens_per_algorithm))\n",
    "df_single_fixation_probability = df_single_fixation_probability.reset_index()\n",
    "\n",
    "# Probability of multiple fixation\n",
    "df_multiple_fixation_probability = multiple_fixation_per_algorithm.groupby([\"Participant\", \"Algorithm\"]).apply(lambda df: group_len_divided_by_number(df, number_of_tokens_per_algorithm))\n",
    "df_multiple_fixation_probability = df_multiple_fixation_probability.reset_index()\n",
    "\n",
    "# Probability of fixation\n",
    "df_fixation_probability = fixations_per_algorithm.groupby([\"Participant\", \"Algorithm\"]).apply(lambda df: group_len_divided_by_number(df, number_of_tokens_per_algorithm))\n",
    "df_fixation_probability = df_fixation_probability.reset_index()\n",
    "\n",
    "# Calculate the means for the metrics per algorithm\n",
    "df_no_fixation_probability = df_no_fixation_probability.groupby([\"Participant\"]).mean()\n",
    "df_single_fixation_probability = df_single_fixation_probability.groupby([\"Participant\"]).mean()\n",
    "df_multiple_fixation_probability = df_multiple_fixation_probability.groupby([\"Participant\"]).mean()\n",
    "df_fixation_probability = df_fixation_probability.groupby([\"Participant\"]).mean()\n",
    "\n",
    "# Raw Durations Metrics\n",
    "# Duration of first fixation\n",
    "df_first_fixation = df_metrics_skill[~df_metrics_skill[\"FirstFixationDuration\"].isnull()]\n",
    "df_first_fixation = df_first_fixation.groupby([\"Participant\"])[\"FirstFixationDuration\"].mean()\n",
    "\n",
    "# Duration of single fixation\n",
    "df_single_fixation = df_metrics_skill[~df_metrics_skill[\"SingleFixationDuration\"].isnull()]\n",
    "df_single_fixation = df_single_fixation.groupby([\"Participant\"])[\"SingleFixationDuration\"].mean()\n",
    "\n",
    "# Duration of gaze duration\n",
    "df_gaze_duration = df_metrics_skill[~df_metrics_skill[\"GazeDuration\"].isnull()]\n",
    "df_gaze_duration = df_gaze_duration.groupby([\"Participant\"])[\"GazeDuration\"].mean()\n",
    "\n",
    "# Total Time\n",
    "df_total_time = df_metrics_skill[~df_metrics_skill[\"TotalTime\"].isnull()]\n",
    "df_total_time = df_total_time.groupby([\"Participant\"])[\"TotalTime\"].mean()\n",
    "\n",
    "# Put every metric dataframe together into one\n",
    "df_combined = pd.DataFrame({\"FirstFixationDuration\": df_first_fixation.values,\n",
    "                            \"SingleFixationDuration\": df_single_fixation.values,\n",
    "                            \"GazeDuration\": df_gaze_duration.values,\n",
    "                            \"TotalTime\": df_total_time.values,\n",
    "                            \"TokenNoFixationProbability\": df_no_fixation_probability.values.reshape(37, ),\n",
    "                            \"TokenSingleFixationProbability\": df_single_fixation_probability.values.reshape(37, ),\n",
    "                            \"TokenMultipleFixationProbability\": df_multiple_fixation_probability.values.reshape(37, ),\n",
    "                            \"TokenFixationProbability\": df_fixation_probability.values.reshape(37, ),\n",
    "                            \"Skill\": df_metrics_skill.groupby([\"Participant\"])[\"SkillScore\"].mean().values})\n",
    "# get spearman correlation for metrics and skill level\n",
    "df_combined.corr(method=\"spearman\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# AOI based analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Read in the Generator for AOI Based Metrics to get The BoundingBoxes and Indices of each Token per Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9fb4df7cc7d34cbf9ba43bdf5187468e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "     Algorithm                          AOI AOIIdx             BoundingBox\n0      IsPrime            method_identifier      0   (993, 444, 1070, 460)\n1      IsPrime             method_signature      1   (751, 444, 1202, 464)\n2      IsPrime  method_argument_declaration      2  (1070, 444, 1202, 463)\n3      IsPrime                     for_head      3   (795, 469, 1147, 489)\n4      IsPrime        arithmetic_expression      4    (883, 494, 994, 510)\n..         ...                          ...    ...                     ...\n626  Rectangle       method_call_identifier     14  (1048, 769, 1114, 789)\n627  Rectangle             method_arguments     15  (1114, 769, 1136, 788)\n628  Rectangle                  method_call     16   (993, 769, 1136, 789)\n629  Rectangle        arithmetic_expression     17   (828, 769, 1136, 789)\n630  Rectangle            class_declaration     18   (663, 218, 1257, 862)\n\n[631 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Algorithm</th>\n      <th>AOI</th>\n      <th>AOIIdx</th>\n      <th>BoundingBox</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>IsPrime</td>\n      <td>method_identifier</td>\n      <td>0</td>\n      <td>(993, 444, 1070, 460)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>IsPrime</td>\n      <td>method_signature</td>\n      <td>1</td>\n      <td>(751, 444, 1202, 464)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>IsPrime</td>\n      <td>method_argument_declaration</td>\n      <td>2</td>\n      <td>(1070, 444, 1202, 463)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>IsPrime</td>\n      <td>for_head</td>\n      <td>3</td>\n      <td>(795, 469, 1147, 489)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>IsPrime</td>\n      <td>arithmetic_expression</td>\n      <td>4</td>\n      <td>(883, 494, 994, 510)</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>626</th>\n      <td>Rectangle</td>\n      <td>method_call_identifier</td>\n      <td>14</td>\n      <td>(1048, 769, 1114, 789)</td>\n    </tr>\n    <tr>\n      <th>627</th>\n      <td>Rectangle</td>\n      <td>method_arguments</td>\n      <td>15</td>\n      <td>(1114, 769, 1136, 788)</td>\n    </tr>\n    <tr>\n      <th>628</th>\n      <td>Rectangle</td>\n      <td>method_call</td>\n      <td>16</td>\n      <td>(993, 769, 1136, 789)</td>\n    </tr>\n    <tr>\n      <th>629</th>\n      <td>Rectangle</td>\n      <td>arithmetic_expression</td>\n      <td>17</td>\n      <td>(828, 769, 1136, 789)</td>\n    </tr>\n    <tr>\n      <th>630</th>\n      <td>Rectangle</td>\n      <td>class_declaration</td>\n      <td>18</td>\n      <td>(663, 218, 1257, 862)</td>\n    </tr>\n  </tbody>\n</table>\n<p>631 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Token based AOIs\n",
    "snippets = df_fixation[\"Algorithm\"].unique()\n",
    "df_aois = pd.DataFrame(columns=[\"Algorithm\", \"AOI\", \"AOIIdx\", \"BoundingBox\"])\n",
    "for snippet in tqdm(snippets):\n",
    "    aoi_token_generator = f\"./../CodeSnippets/aois/Generators/{snippet}.json\"\n",
    "    try:\n",
    "        image, aoi_list = gsl.create_image(aoi_token_generator, font_path=\"./../CodeSnippets/fonts/ttf/\")\n",
    "    except:\n",
    "        print(f\"{snippet} failed\")\n",
    "        image, aoi_list = gsl.create_image(aoi_token_generator, font_path=\"./../CodeSnippets/fonts/ttf/\", logging=True)\n",
    "        break\n",
    "    height, width = image.size\n",
    "    width_offset = int(1920 * 0.5) - int(height / 2)\n",
    "    height_offset = int(1080 * 0.5) - int(width / 2)\n",
    "    aoi_clustered = []\n",
    "    current_left = []\n",
    "    current_top = []\n",
    "    current_right = []\n",
    "    current_bottom = []\n",
    "    current_aoi = []\n",
    "    color = []\n",
    "    for letter in aoi_list:\n",
    "        # Close AOI\n",
    "        if letter['letter'] in \" \\t\\n\":\n",
    "            continue\n",
    "        if len(letter[\"AOI\"]) == 1:\n",
    "            for idx in range(len(current_aoi)):\n",
    "                aoi_clustered.append((len(aoi_clustered), current_aoi[idx], current_left[idx], current_top[idx], current_right[idx], current_bottom[idx], color[idx]))\n",
    "\n",
    "            current_aoi = []\n",
    "            color = []\n",
    "            current_left = []\n",
    "            current_top = []\n",
    "            current_right = []\n",
    "            current_bottom = []\n",
    "            continue\n",
    "        # There is no AOI set\n",
    "        if len(current_aoi) == 0:\n",
    "            current_aoi = []\n",
    "            color = []\n",
    "            current_left = []\n",
    "            current_top = []\n",
    "            current_right = []\n",
    "            current_bottom = []\n",
    "            for idx in range(1, len(letter[\"AOI\"])):\n",
    "                current_aoi.append(letter[\"AOI\"][idx])\n",
    "                current_left.append(letter[\"BoundingBox\"][0])\n",
    "                current_top.append(letter[\"BoundingBox\"][1])\n",
    "                current_right.append(letter[\"BoundingBox\"][2])\n",
    "                current_bottom.append(letter[\"BoundingBox\"][3])\n",
    "                color.append(letter[\"color\"])\n",
    "            continue\n",
    "\n",
    "\n",
    "        for idx in reversed(range(len(current_aoi))):\n",
    "            if current_aoi[idx] in letter[\"AOI\"]:\n",
    "                current_left[idx] = min(current_left[idx], letter[\"BoundingBox\"][0])\n",
    "                current_top[idx] = min(current_top[idx], letter[\"BoundingBox\"][1])\n",
    "                current_right[idx] = max(current_right[idx], letter[\"BoundingBox\"][2])\n",
    "                current_bottom[idx] = max(current_bottom[idx], letter[\"BoundingBox\"][3])\n",
    "                # remove the AOI from the letter\n",
    "                letter[\"AOI\"].remove(current_aoi[idx])\n",
    "            else:\n",
    "                aoi_clustered.append((len(aoi_clustered), current_aoi[idx], current_left[idx], current_top[idx], current_right[idx], current_bottom[idx], color[idx]))\n",
    "                del current_aoi[idx]\n",
    "                del current_left[idx]\n",
    "                del current_top[idx]\n",
    "                del current_right[idx]\n",
    "                del current_bottom[idx]\n",
    "                del color[idx]\n",
    "\n",
    "        for idx in range(1, len(letter[\"AOI\"])):\n",
    "            current_aoi.append(letter[\"AOI\"][idx])\n",
    "            current_left.append(letter[\"BoundingBox\"][0])\n",
    "            current_top.append(letter[\"BoundingBox\"][1])\n",
    "            current_right.append(letter[\"BoundingBox\"][2])\n",
    "            current_bottom.append(letter[\"BoundingBox\"][3])\n",
    "            color.append(letter[\"color\"])\n",
    "\n",
    "    for idx in range(len(current_aoi)):\n",
    "        aoi_clustered.append((len(aoi_clustered), current_aoi[idx], current_left[idx], current_top[idx], current_right[idx], current_bottom[idx], color[idx]))\n",
    "\n",
    "    for token in aoi_clustered:\n",
    "        df_aois.loc[len(df_aois)] = [snippet, token[1], token[0],\n",
    "                                                 (token[2] + width_offset,\n",
    "                                                  token[3] + height_offset,\n",
    "                                                  token[4] + width_offset,\n",
    "                                                  token[5] + height_offset)]\n",
    "\n",
    "df_aois"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Check which Fixation of which Participant is in which AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e8900b22e9fc43e3837bad9b778c5391"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ceeab4fe69704470ab4b45b26658c66e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1bcc3890e2664c53863dc0ea14b8a843"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "580d0892478d43848987a17024e45ae4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0b49f629af9c4357b49606fdd4f57259"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bb25e7a0ddb14687898a07cbe735cb93"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d55918e1da864eac9c3fa1b8b9548ed5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "37750a81a71e4030a96e7308f70cf667"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a842bc300a2a4b5e8a0b16143c43b77a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a6f5215fd10d44cab663e8adad6b6ab2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "42e1b558eb4e4fb4bdf12ad461d1e4bf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ce2e426772274ed580ff7d2c7db17fed"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e84eb6b5a32f4e33b7051392765dcc4c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0ea3d3553110467aa9a135a687d8e0ad"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f4b06735ca8a40c99932adaa44ebc645"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ef58b51b9cdd4e0fb94fa153b820297b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4337f682a5574cafa4b545aad8c9a600"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1a17f39c2dd449458eae441fb743d798"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f67b976257334e25bad069f3c31c8600"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "788dd465c66748998b6c2e3338ad4e41"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e6a34ee21eca4409b5c1b1655589deca"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "24a0fad87a32440e94bdb4506dc1f17f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "384dc25bb7b34466905845806e9fe466"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b8811e1ed51e41b29a590584317238ee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "68d17cdfb907498fbfc56351e5105c85"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d790387f91494405a82307f757e7653d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1358cf3c1cce457ab76456fae317e487"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "262531c543d947c1a71d14cb8487abb3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "03413bfd214f407d9841816d2e9bb1ba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ea65738cbae04e5080bd0af57c348cb0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "504d8a2cbdc84ef0b2b7b69fd0766f1e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0445c9eaa1594f5b8cf1ccc6347c0996"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c6987c066bdc4239bc3fc0754b5d3aca"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_aoi_fixation_per_participant = pd.DataFrame([], columns=[\"Algorithm\", \"Participant\", \"FixationNumber\",\n",
    "                                                              \"FixationDuration\", \"AOIIdx\", \"AOIName\"])\n",
    "participants = df_fixation[\"Participant\"].unique()\n",
    "for snippet in tqdm(snippets):\n",
    "    df_aois_per_algo = df_aois[df_aois[\"Algorithm\"] == snippet]\n",
    "\n",
    "    for participant in tqdm(participants):\n",
    "\n",
    "        df_fixation_participant = df_fixation[(df_fixation[\"Algorithm\"] == snippet) & (df_fixation[\"Participant\"] == participant)]\n",
    "        if len(df_fixation_participant) == 0:\n",
    "            continue\n",
    "        start_times = eval(df_fixation_participant[\"Fixation_startT\"].values[0])\n",
    "        end_times = eval(df_fixation_participant[\"Fixation_endT\"].values[0])\n",
    "        x_coordinates = eval(df_fixation_participant[\"Fixation_x\"].values[0])\n",
    "        y_coordinates = eval(df_fixation_participant[\"Fixation_y\"].values[0])\n",
    "        x_range = eval(df_fixation_participant[\"Fixation_x_range\"].values[0])\n",
    "        y_range = eval(df_fixation_participant[\"Fixation_y_range\"].values[0])\n",
    "        idx_values = range(len(start_times))\n",
    "        for (fix_idx, start, end, x, y, x_range, y_range) in zip(idx_values, start_times, end_times, x_coordinates, y_coordinates, x_range, y_range):\n",
    "            low_x = int(float(x) - math.ceil(float(x_range)))\n",
    "            low_y = int(float(y) - math.ceil(float(y_range)))\n",
    "            high_x = int(float(x) + math.ceil(float(x_range)))\n",
    "            high_y = int(float(y) + math.ceil(float(y_range)))\n",
    "            possible_coordinates = [(x, y) for x in range(low_x, high_x + 1) for y in range(low_y, high_y + 1)]\n",
    "\n",
    "            for idx, row in df_aois_per_algo.iterrows():\n",
    "                aoi_idx = row[\"AOIIdx\"]\n",
    "                aoi_name = row[\"AOI\"]\n",
    "                bounding_box = row[\"BoundingBox\"]\n",
    "\n",
    "                for possible_x, possible_y in possible_coordinates:\n",
    "                    if bounding_box[0] <= possible_x <= bounding_box[2] and bounding_box[1] <= possible_y <=bounding_box[3]:\n",
    "                        df_aoi_fixation_per_participant.loc[len(df_aoi_fixation_per_participant)] = [snippet, participant, fix_idx ,end - start, aoi_idx, aoi_name]\n",
    "                        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "### Transform the Data to a Fixation/ Refixation split by Participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/37386 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f6700f300eac4c26a10a78d6c451a5d5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_token = df_token_aois.copy()\n",
    "df_token = df_token.drop([\"BoundingBox\", \"Token\"], axis=1)\n",
    "for participant in participants:\n",
    "    df_token.loc[:, f\"TokenFixation_P{participant}\"] = [[] for _ in range(len(df_token))]\n",
    "    df_token.loc[:, f\"TokenReFixation_P{participant}\"] = [[] for _ in range(len(df_token))]\n",
    "\n",
    "\n",
    "prev_participant = df_token_fixation_per_participant[\"Participant\"].iloc[0]\n",
    "prev_token_idx = df_token_fixation_per_participant[\"TokenIdx\"].iloc[0]\n",
    "prev_algorithm = df_token_fixation_per_participant[\"Algorithm\"].iloc[0]\n",
    "fixations = []\n",
    "re_fixation = False\n",
    "for idx, row in tqdm(df_token_fixation_per_participant.iterrows(), total=len(df_token_fixation_per_participant)):\n",
    "    participant = row[\"Participant\"]\n",
    "    token_idx = row[\"TokenIdx\"]\n",
    "    algorithm = row[\"Algorithm\"]\n",
    "    FixationDuration = row[\"FixationDuration\"]\n",
    "\n",
    "    # fixation switches\n",
    "    if prev_participant != participant or prev_token_idx != token_idx:\n",
    "        index = df_token[(df_token[\"TokenIdx\"] == prev_token_idx) & (df_token[\"Algorithm\"] == prev_algorithm)].index[0]\n",
    "        if re_fixation:\n",
    "            re_fixations = df_token.loc[index, f\"TokenReFixation_P{prev_participant}\"]\n",
    "            re_fixations.extend(fixations.copy())\n",
    "            df_token.loc[index, f\"TokenReFixation_P{prev_participant}\"] = re_fixations.copy()\n",
    "        else:\n",
    "            df_token.loc[index, f\"TokenFixation_P{prev_participant}\"] = fixations.copy()\n",
    "        fixations = []\n",
    "        # possible new fixation\n",
    "        re_fixation = False\n",
    "\n",
    "    sub_frame = df_token[(df_token[\"TokenIdx\"] == token_idx) & (df_token[\"Algorithm\"] == algorithm)]\n",
    "    if len(sub_frame) == 0:\n",
    "        raise Exception(f\"No Token found for {token_idx} in Algorithm {algorithm}\")\n",
    "    len_of_fixation = len(sub_frame[f\"TokenFixation_P{participant}\"].iloc[0])\n",
    "    if re_fixation == False and len_of_fixation > 0 and len(fixations) == 0:\n",
    "        re_fixation = True\n",
    "\n",
    "    fixations.append(FixationDuration)\n",
    "    prev_participant = participant\n",
    "    prev_token_idx = token_idx\n",
    "    prev_algorithm = algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Calculate the AOI Based Eyetracking Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                  FirstFixationDuration  \\\nFirstFixationDuration                          1.000000   \nSingleFixationDuration                         0.995258   \nGazeDuration                                   0.970602   \nTotalTime                                      0.822191   \nTokenNoFixationProbability                     0.122333   \nTokenSingleFixationProbability                 0.117117   \nTokenMultipleFixationProbability              -0.070175   \nTokenFixationProbability                       0.083452   \nSkill                                         -0.141299   \n\n                                  SingleFixationDuration  GazeDuration  \\\nFirstFixationDuration                           0.995258      0.970602   \nSingleFixationDuration                          1.000000      0.968468   \nGazeDuration                                    0.968468      1.000000   \nTotalTime                                       0.823850      0.781650   \nTokenNoFixationProbability                      0.130394      0.174964   \nTokenSingleFixationProbability                  0.117591      0.066619   \nTokenMultipleFixationProbability               -0.064011     -0.136795   \nTokenFixationProbability                        0.059033      0.120199   \nSkill                                          -0.143433     -0.188952   \n\n                                  TotalTime  TokenNoFixationProbability  \\\nFirstFixationDuration              0.822191                    0.122333   \nSingleFixationDuration             0.823850                    0.130394   \nGazeDuration                       0.781650                    0.174964   \nTotalTime                          1.000000                   -0.040778   \nTokenNoFixationProbability        -0.040778                    1.000000   \nTokenSingleFixationProbability     0.271930                   -0.740161   \nTokenMultipleFixationProbability   0.287340                   -0.717639   \nTokenFixationProbability           0.307729                   -0.541489   \nSkill                             -0.370792                    0.081555   \n\n                                  TokenSingleFixationProbability  \\\nFirstFixationDuration                                   0.117117   \nSingleFixationDuration                                  0.117591   \nGazeDuration                                            0.066619   \nTotalTime                                               0.271930   \nTokenNoFixationProbability                             -0.740161   \nTokenSingleFixationProbability                          1.000000   \nTokenMultipleFixationProbability                        0.800379   \nTokenFixationProbability                                0.625652   \nSkill                                                  -0.311759   \n\n                                  TokenMultipleFixationProbability  \\\nFirstFixationDuration                                    -0.070175   \nSingleFixationDuration                                   -0.064011   \nGazeDuration                                             -0.136795   \nTotalTime                                                 0.287340   \nTokenNoFixationProbability                               -0.717639   \nTokenSingleFixationProbability                            0.800379   \nTokenMultipleFixationProbability                          1.000000   \nTokenFixationProbability                                  0.646278   \nSkill                                                    -0.374111   \n\n                                  TokenFixationProbability     Skill  \nFirstFixationDuration                             0.083452 -0.141299  \nSingleFixationDuration                            0.059033 -0.143433  \nGazeDuration                                      0.120199 -0.188952  \nTotalTime                                         0.307729 -0.370792  \nTokenNoFixationProbability                       -0.541489  0.081555  \nTokenSingleFixationProbability                    0.625652 -0.311759  \nTokenMultipleFixationProbability                  0.646278 -0.374111  \nTokenFixationProbability                          1.000000 -0.586297  \nSkill                                            -0.586297  1.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FirstFixationDuration</th>\n      <th>SingleFixationDuration</th>\n      <th>GazeDuration</th>\n      <th>TotalTime</th>\n      <th>TokenNoFixationProbability</th>\n      <th>TokenSingleFixationProbability</th>\n      <th>TokenMultipleFixationProbability</th>\n      <th>TokenFixationProbability</th>\n      <th>Skill</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>FirstFixationDuration</th>\n      <td>1.000000</td>\n      <td>0.995258</td>\n      <td>0.970602</td>\n      <td>0.822191</td>\n      <td>0.122333</td>\n      <td>0.117117</td>\n      <td>-0.070175</td>\n      <td>0.083452</td>\n      <td>-0.141299</td>\n    </tr>\n    <tr>\n      <th>SingleFixationDuration</th>\n      <td>0.995258</td>\n      <td>1.000000</td>\n      <td>0.968468</td>\n      <td>0.823850</td>\n      <td>0.130394</td>\n      <td>0.117591</td>\n      <td>-0.064011</td>\n      <td>0.059033</td>\n      <td>-0.143433</td>\n    </tr>\n    <tr>\n      <th>GazeDuration</th>\n      <td>0.970602</td>\n      <td>0.968468</td>\n      <td>1.000000</td>\n      <td>0.781650</td>\n      <td>0.174964</td>\n      <td>0.066619</td>\n      <td>-0.136795</td>\n      <td>0.120199</td>\n      <td>-0.188952</td>\n    </tr>\n    <tr>\n      <th>TotalTime</th>\n      <td>0.822191</td>\n      <td>0.823850</td>\n      <td>0.781650</td>\n      <td>1.000000</td>\n      <td>-0.040778</td>\n      <td>0.271930</td>\n      <td>0.287340</td>\n      <td>0.307729</td>\n      <td>-0.370792</td>\n    </tr>\n    <tr>\n      <th>TokenNoFixationProbability</th>\n      <td>0.122333</td>\n      <td>0.130394</td>\n      <td>0.174964</td>\n      <td>-0.040778</td>\n      <td>1.000000</td>\n      <td>-0.740161</td>\n      <td>-0.717639</td>\n      <td>-0.541489</td>\n      <td>0.081555</td>\n    </tr>\n    <tr>\n      <th>TokenSingleFixationProbability</th>\n      <td>0.117117</td>\n      <td>0.117591</td>\n      <td>0.066619</td>\n      <td>0.271930</td>\n      <td>-0.740161</td>\n      <td>1.000000</td>\n      <td>0.800379</td>\n      <td>0.625652</td>\n      <td>-0.311759</td>\n    </tr>\n    <tr>\n      <th>TokenMultipleFixationProbability</th>\n      <td>-0.070175</td>\n      <td>-0.064011</td>\n      <td>-0.136795</td>\n      <td>0.287340</td>\n      <td>-0.717639</td>\n      <td>0.800379</td>\n      <td>1.000000</td>\n      <td>0.646278</td>\n      <td>-0.374111</td>\n    </tr>\n    <tr>\n      <th>TokenFixationProbability</th>\n      <td>0.083452</td>\n      <td>0.059033</td>\n      <td>0.120199</td>\n      <td>0.307729</td>\n      <td>-0.541489</td>\n      <td>0.625652</td>\n      <td>0.646278</td>\n      <td>1.000000</td>\n      <td>-0.586297</td>\n    </tr>\n    <tr>\n      <th>Skill</th>\n      <td>-0.141299</td>\n      <td>-0.143433</td>\n      <td>-0.188952</td>\n      <td>-0.370792</td>\n      <td>0.081555</td>\n      <td>-0.311759</td>\n      <td>-0.374111</td>\n      <td>-0.586297</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Melt the Dataframe to be thinner so that we have Algorithm TokenIdx and Participant and Keys per Fixation / Refixation\n",
    "df_token_melted = pd.melt(df_token, id_vars=[\"Algorithm\", \"TokenIdx\"], var_name=\"KindOfFixation\", value_name=\"FixationDurations\")\n",
    "\n",
    "# Classify Participant and the Kind and Number of Fixations / Refixations\n",
    "df_token_melted[\"Participant\"] = df_token_melted[\"KindOfFixation\"].apply(lambda x: int(x.split(\"_\")[1][1:]))\n",
    "df_token_melted[\"KindOfFixation\"] = df_token_melted[\"KindOfFixation\"].apply(lambda x: x.split(\"_\")[0])\n",
    "df_token_melted[\"KindOfFixation\"] = df_token_melted[\"KindOfFixation\"].apply(lambda x: \"Fixation\" if x == \"TokenFixation\" else \"ReFixation\")\n",
    "df_token_melted[\"NumberOfFixations\"] = df_token_melted[\"FixationDurations\"].apply(lambda x: len(x))\n",
    "\n",
    "# Get the number of Participants for further calculations\n",
    "number_of_participants = len(participants)\n",
    "\n",
    "# Calculate the First Fixation Duration per Participant per Token\n",
    "df_token_melted[\"FirstFixationDuration\"] = None\n",
    "df_token_melted.loc[df_token_melted[\"KindOfFixation\"] == \"Fixation\" , \"FirstFixationDuration\"] = df_token_melted[\"FixationDurations\"]\\\n",
    "    .apply(lambda x: x[0] if len(x) > 0 else None)\n",
    "\n",
    "# Calculate the Single Fixation Duration per Participant per Token\n",
    "df_token_melted[\"SingleFixationDuration\"] = None\n",
    "df_token_melted.loc[df_token_melted[\"KindOfFixation\"] == \"Fixation\" , \"SingleFixationDuration\"] = df_token_melted[\"FixationDurations\"]\\\n",
    "    .apply(lambda x: x[0] if len(x) == 1 else None)\n",
    "\n",
    "# Calculate the Gaze Duration per Participant per Token\n",
    "df_token_melted[\"GazeDuration\"] = None\n",
    "df_token_melted.loc[df_token_melted[\"KindOfFixation\"] == \"Fixation\" , \"GazeDuration\"] = df_token_melted[\"FixationDurations\"]\\\n",
    "    .apply(lambda x: sum(x) if len(x) > 0 else None)\n",
    "\n",
    "# Calculate the Total Time per Participant per Token\n",
    "df_token_melted_total_time = df_token_melted.groupby([\"Participant\", \"Algorithm\", \"TokenIdx\"])\\\n",
    "    .agg({\"FixationDurations\": lambda x: sum(x.values.sum())})\n",
    "df_token_melted_total_time = df_token_melted_total_time.rename(columns={\"FixationDurations\": \"TotalTime\"})\n",
    "\n",
    "# Merge the Dataframes\n",
    "df_token_melted = pd.merge(df_token_melted, df_token_melted_total_time, on=[\"Participant\", \"Algorithm\", \"TokenIdx\"], how=\"left\")\n",
    "\n",
    "# Cast the Dataframes to the right datatype\n",
    "df_token_melted[\"FirstFixationDuration\"] = df_token_melted[\"FirstFixationDuration\"].astype(float)\n",
    "df_token_melted[\"SingleFixationDuration\"] = df_token_melted[\"SingleFixationDuration\"].astype(float)\n",
    "df_token_melted[\"GazeDuration\"] = df_token_melted[\"GazeDuration\"].astype(float)\n",
    "df_token_melted[\"TotalTime\"] = df_token_melted[\"TotalTime\"].astype(float).replace(0, np.nan)\n",
    "\n",
    "# Read in the Skilllevel\n",
    "df_skill = pd.read_csv(f\"./data/filteredData/filtered_data.csv\")\n",
    "df_skill = df_skill[[\"Participant\", \"SkillScore\"]]\n",
    "df_skill = df_skill.drop_duplicates()\n",
    "\n",
    "# Merge the Dataframes to combine metrics with the Skilllevel\n",
    "df_metrics_skill = pd.merge(df_token_melted, df_skill, on=[\"Participant\"], how=\"left\")\n",
    "\n",
    "# Helper Methods for the Metrics\n",
    "def get_single_fixations(df):\n",
    "    df_fixations = df[df[\"KindOfFixation\"] == \"Fixation\"]\n",
    "    df_refixations = df[df[\"KindOfFixation\"] == \"ReFixation\"]\n",
    "    df_refixations = df_refixations[df_refixations[\"NumberOfFixations\"] > 0]\n",
    "    # remove every entry from df fixations on [\"Algorithm\", \"TokenIdx\"] where there is a refixation6\n",
    "    df_fixations = df_fixations[~df_fixations[\"TokenIdx\"].isin(df_refixations[\"TokenIdx\"].values)]\n",
    "    # remove every entry from df fixations on where Number Of Fixations is not 1\n",
    "    df_fixations = df_fixations[df_fixations[\"NumberOfFixations\"] == 1]\n",
    "    return df_fixations\n",
    "\n",
    "def get_no_fixations(df):\n",
    "    df_fixations = df[df[\"KindOfFixation\"] == \"Fixation\"]\n",
    "    # remove every entry from df fixations on [\"Algorithm\", \"TokenIdx\"] where there is a refixation6\n",
    "    df_fixations = df_fixations[df_fixations[\"NumberOfFixations\"] == 0]\n",
    "    return df_fixations\n",
    "\n",
    "\n",
    "def get_fixations(df):\n",
    "    df_fixations = df[df[\"KindOfFixation\"] == \"Fixation\"]\n",
    "    df_refixations = df[df[\"KindOfFixation\"] == \"ReFixation\"]\n",
    "    df_refixations = df_refixations[df_refixations[\"NumberOfFixations\"] > 0]\n",
    "    # remove every entry from df fixations on [\"Algorithm\", \"TokenIdx\"] where there is a refixation6\n",
    "    df_fixations = df_fixations[~df_fixations[\"TokenIdx\"].isin(df_refixations[\"TokenIdx\"].values)]\n",
    "    # remove every entry from df fixations on where Number Of Fixations is not 1\n",
    "    df_fixations = df_fixations[df_fixations[\"NumberOfFixations\"] > 1]\n",
    "    return df_fixations\n",
    "\n",
    "def get_multiple_fixations(df):\n",
    "    df_fixations = df[df[\"KindOfFixation\"] == \"Fixation\"]\n",
    "    df_refixations = df[df[\"KindOfFixation\"] == \"ReFixation\"]\n",
    "    df_refixations = df_refixations[df_refixations[\"NumberOfFixations\"] > 0]\n",
    "    # remove every entry from df fixations on [\"Algorithm\", \"TokenIdx\"] where there is a refixation6\n",
    "    df_fixations = df_fixations[(df_fixations[\"TokenIdx\"].isin(df_refixations[\"TokenIdx\"].values)) & (df_fixations[\"NumberOfFixations\"] >= 1)]\n",
    "    return df_fixations\n",
    "\n",
    "def get_fixations(df):\n",
    "    df_fixations = df[df[\"KindOfFixation\"] == \"Fixation\"]\n",
    "    # remove every entry from df fixations on where no Fixation is found\n",
    "    df_fixations = df_fixations[df_fixations[\"NumberOfFixations\"] > 1]\n",
    "    return df_fixations\n",
    "\n",
    "\n",
    "\n",
    "# dataframe for number of fixations per participant\n",
    "number_of_fixation_per_algorithm = df_metrics_skill.groupby([\"Participant\", \"Algorithm\"])[\"NumberOfFixations\"].count()\n",
    "number_of_fixation_per_algorithm = number_of_fixation_per_algorithm.reset_index()\n",
    "\n",
    "# dataframe for number of tokens per algorithm\n",
    "number_of_tokens_per_algorithm = df_metrics_skill.groupby([\"Algorithm\"])[\"TokenIdx\"].max()\n",
    "number_of_tokens_per_algorithm = number_of_tokens_per_algorithm.reset_index()\n",
    "\n",
    "# dataframe for number of tokens with no fixation per algorithm per participant\n",
    "df_no_fixation_per_algorithm = df_metrics_skill.groupby([\"Participant\", \"Algorithm\"])\\\n",
    "    .apply(get_no_fixations)\\\n",
    "    .drop([\"Algorithm\"], axis=1)\n",
    "\n",
    "# dataframe for number of tokens with only one fixation per algorithm per participant\n",
    "df_single_fixation_per_algorithm = df_metrics_skill.groupby([\"Participant\", \"Algorithm\"])\\\n",
    "    .apply(get_single_fixations)\\\n",
    "    .drop([\"Algorithm\"], axis=1)\n",
    "\n",
    "# dataframe for number of tokens with more than one fixation per algorithm per participant\n",
    "df_multiple_fixation_per_algorithm = df_metrics_skill.groupby([\"Participant\", \"Algorithm\"])\\\n",
    "    .apply(get_multiple_fixations)\\\n",
    "    .drop([\"Algorithm\"], axis=1)\n",
    "\n",
    "# dataframe for number of tokens with more or equal than one fixation per algorithm per participant\n",
    "df_fixation_per_algorithm = df_metrics_skill.groupby([\"Participant\", \"Algorithm\"])\\\n",
    "    .apply(get_fixations)\\\n",
    "    .drop([\"Algorithm\"], axis=1)\n",
    "\n",
    "# Reformat the dataframes\n",
    "no_fixation_per_algorithm = df_no_fixation_per_algorithm[[\"TokenIdx\"]]\n",
    "no_fixation_per_algorithm = no_fixation_per_algorithm.reset_index().drop([\"level_2\"], axis=1)\n",
    "\n",
    "single_fixation_per_algorithm = df_single_fixation_per_algorithm[[\"TokenIdx\"]]\n",
    "single_fixation_per_algorithm = single_fixation_per_algorithm.reset_index().drop([\"level_2\"], axis=1)\n",
    "\n",
    "multiple_fixation_per_algorithm = df_multiple_fixation_per_algorithm[[\"TokenIdx\"]]\n",
    "multiple_fixation_per_algorithm = multiple_fixation_per_algorithm.reset_index().drop([\"level_2\"], axis=1)\n",
    "\n",
    "fixations_per_algorithm = df_fixation_per_algorithm[[\"TokenIdx\"]]\n",
    "fixations_per_algorithm = fixations_per_algorithm.reset_index().drop([\"level_2\"], axis=1)\n",
    "\n",
    "# Helper Method for Probability Metrics\n",
    "def group_len_divided_by_number(current_df, counting_df):\n",
    "    algorithm = current_df[\"Algorithm\"].iloc[0]\n",
    "    number_of_tokens = counting_df[counting_df[\"Algorithm\"] == algorithm][\"TokenIdx\"].iloc[0]\n",
    "    value = len(current_df) / number_of_tokens\n",
    "    return len(current_df) / (number_of_tokens + 1)\n",
    "\n",
    "# Calculate the Metrics per Participant\n",
    "# Probability of no fixation\n",
    "df_no_fixation_probability = no_fixation_per_algorithm.groupby([\"Participant\", \"Algorithm\"]).apply(lambda df: group_len_divided_by_number(df, number_of_tokens_per_algorithm))\n",
    "df_no_fixation_probability = df_no_fixation_probability.reset_index()\n",
    "\n",
    "# Probability of single fixation\n",
    "df_single_fixation_probability = single_fixation_per_algorithm.groupby([\"Participant\", \"Algorithm\"]).apply(lambda df: group_len_divided_by_number(df, number_of_tokens_per_algorithm))\n",
    "df_single_fixation_probability = df_single_fixation_probability.reset_index()\n",
    "\n",
    "# Probability of multiple fixation\n",
    "df_multiple_fixation_probability = multiple_fixation_per_algorithm.groupby([\"Participant\", \"Algorithm\"]).apply(lambda df: group_len_divided_by_number(df, number_of_tokens_per_algorithm))\n",
    "df_multiple_fixation_probability = df_multiple_fixation_probability.reset_index()\n",
    "\n",
    "# Probability of fixation\n",
    "df_fixation_probability = fixations_per_algorithm.groupby([\"Participant\", \"Algorithm\"]).apply(lambda df: group_len_divided_by_number(df, number_of_tokens_per_algorithm))\n",
    "df_fixation_probability = df_fixation_probability.reset_index()\n",
    "\n",
    "# Calculate the means for the metrics per algorithm\n",
    "df_no_fixation_probability = df_no_fixation_probability.groupby([\"Participant\"]).mean()\n",
    "df_single_fixation_probability = df_single_fixation_probability.groupby([\"Participant\"]).mean()\n",
    "df_multiple_fixation_probability = df_multiple_fixation_probability.groupby([\"Participant\"]).mean()\n",
    "df_fixation_probability = df_fixation_probability.groupby([\"Participant\"]).mean()\n",
    "\n",
    "# Raw Durations Metrics\n",
    "# Duration of first fixation\n",
    "df_first_fixation = df_metrics_skill[~df_metrics_skill[\"FirstFixationDuration\"].isnull()]\n",
    "df_first_fixation = df_first_fixation.groupby([\"Participant\"])[\"FirstFixationDuration\"].mean()\n",
    "\n",
    "# Duration of single fixation\n",
    "df_single_fixation = df_metrics_skill[~df_metrics_skill[\"SingleFixationDuration\"].isnull()]\n",
    "df_single_fixation = df_single_fixation.groupby([\"Participant\"])[\"SingleFixationDuration\"].mean()\n",
    "\n",
    "# Duration of gaze duration\n",
    "df_gaze_duration = df_metrics_skill[~df_metrics_skill[\"GazeDuration\"].isnull()]\n",
    "df_gaze_duration = df_gaze_duration.groupby([\"Participant\"])[\"GazeDuration\"].mean()\n",
    "\n",
    "# Total Time\n",
    "df_total_time = df_metrics_skill[~df_metrics_skill[\"TotalTime\"].isnull()]\n",
    "df_total_time = df_total_time.groupby([\"Participant\"])[\"TotalTime\"].mean()\n",
    "\n",
    "# Put every metric dataframe together into one\n",
    "df_combined = pd.DataFrame({\"FirstFixationDuration\": df_first_fixation.values,\n",
    "                            \"SingleFixationDuration\": df_single_fixation.values,\n",
    "                            \"GazeDuration\": df_gaze_duration.values,\n",
    "                            \"TotalTime\": df_total_time.values,\n",
    "                            \"TokenNoFixationProbability\": df_no_fixation_probability.values.reshape(37, ),\n",
    "                            \"TokenSingleFixationProbability\": df_single_fixation_probability.values.reshape(37, ),\n",
    "                            \"TokenMultipleFixationProbability\": df_multiple_fixation_probability.values.reshape(37, ),\n",
    "                            \"TokenFixationProbability\": df_fixation_probability.values.reshape(37, ),\n",
    "                            \"Skill\": df_metrics_skill.groupby([\"Participant\"])[\"SkillScore\"].mean().values})\n",
    "# get spearman correlation for metrics and skill level\n",
    "df_combined.corr(method=\"spearman\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Get the LOCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1f7f2e3a580d4d65b49cfb3c18968b38"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "     Algorithm Line            BoundingBox\n0      IsPrime    0  (768, 467, 1152, 482)\n1      IsPrime    1  (768, 486, 1112, 501)\n2      IsPrime    2  (768, 505, 1049, 519)\n3      IsPrime    3  (768, 526, 1008, 539)\n4      IsPrime    4   (768, 543, 880, 557)\n..         ...  ...                    ...\n429  Rectangle   12  (740, 601, 1012, 615)\n430  Rectangle   13   (740, 619, 788, 633)\n431  Rectangle   15   (740, 657, 956, 672)\n432  Rectangle   16  (740, 676, 1100, 691)\n433  Rectangle   17   (740, 695, 788, 709)\n\n[434 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Algorithm</th>\n      <th>Line</th>\n      <th>BoundingBox</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>IsPrime</td>\n      <td>0</td>\n      <td>(768, 467, 1152, 482)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>IsPrime</td>\n      <td>1</td>\n      <td>(768, 486, 1112, 501)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>IsPrime</td>\n      <td>2</td>\n      <td>(768, 505, 1049, 519)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>IsPrime</td>\n      <td>3</td>\n      <td>(768, 526, 1008, 539)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>IsPrime</td>\n      <td>4</td>\n      <td>(768, 543, 880, 557)</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>429</th>\n      <td>Rectangle</td>\n      <td>12</td>\n      <td>(740, 601, 1012, 615)</td>\n    </tr>\n    <tr>\n      <th>430</th>\n      <td>Rectangle</td>\n      <td>13</td>\n      <td>(740, 619, 788, 633)</td>\n    </tr>\n    <tr>\n      <th>431</th>\n      <td>Rectangle</td>\n      <td>15</td>\n      <td>(740, 657, 956, 672)</td>\n    </tr>\n    <tr>\n      <th>432</th>\n      <td>Rectangle</td>\n      <td>16</td>\n      <td>(740, 676, 1100, 691)</td>\n    </tr>\n    <tr>\n      <th>433</th>\n      <td>Rectangle</td>\n      <td>17</td>\n      <td>(740, 695, 788, 709)</td>\n    </tr>\n  </tbody>\n</table>\n<p>434 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Bounding Boxes for Lines Of Code\n",
    "snippets = df_fixation[\"Algorithm\"].unique()\n",
    "df_lines = pd.DataFrame(columns=[\"Algorithm\", \"Line\", \"BoundingBox\"])\n",
    "for snippet in tqdm(snippets):\n",
    "    aoi_token_generator = f\"./../CodeSnippets/aois/Generators/{snippet}_ast.json\"\n",
    "    image, aoi_list = gsl.create_image(aoi_token_generator, font_path=\"./../CodeSnippets/fonts/ttf/\")\n",
    "    height, width = image.size\n",
    "    width_offset = int(1920 * 0.5) - int(height / 2)\n",
    "    height_offset = int(1080 * 0.5) - int(width / 2)\n",
    "    aoi_clustered = []\n",
    "    current_left = None\n",
    "    current_top = None\n",
    "    current_right = None\n",
    "    current_bottom = None\n",
    "    current_line = 0\n",
    "    for letter in aoi_list:\n",
    "        if letter[\"letter\"] == '\\n':\n",
    "            if current_left is not None:\n",
    "                aoi_clustered.append((current_line, current_left, current_top, current_right, current_bottom))\n",
    "            current_left = None\n",
    "            current_top = None\n",
    "            current_right = None\n",
    "            current_bottom = None\n",
    "            current_line += 1\n",
    "            continue\n",
    "        if current_left is None:\n",
    "            current_left = letter[\"BoundingBox\"][0]\n",
    "            current_top = letter[\"BoundingBox\"][1]\n",
    "            current_right = letter[\"BoundingBox\"][2]\n",
    "            current_bottom = letter[\"BoundingBox\"][3]\n",
    "        else:\n",
    "            current_left = min(current_left, letter[\"BoundingBox\"][0])\n",
    "            current_top = min(current_top, letter[\"BoundingBox\"][1])\n",
    "            current_right = max(current_right, letter[\"BoundingBox\"][2])\n",
    "            current_bottom = max(current_bottom, letter[\"BoundingBox\"][3])\n",
    "\n",
    "    for token in aoi_clustered:\n",
    "        df_lines.loc[len(df_lines)] = [snippet, token[0],\n",
    "                                       (token[1] + width_offset,\n",
    "                                        token[2] + height_offset,\n",
    "                                        token[3] + width_offset,\n",
    "                                        token[4] + height_offset)]\n",
    "df_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6f47779667224de5adb3777fc73513e9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_line_fixation_per_participant = pd.DataFrame([], columns=[\"Algorithm\", \"Participant\", \"FixationNumber\", \"FixationStart\", \"FixationEnd\", \"LineNumber\"])\n",
    "participants = df_fixation[\"Participant\"].unique()\n",
    "for snippet in tqdm(snippets):\n",
    "    df_token_per_algo = df_lines[df_lines[\"Algorithm\"] == snippet]\n",
    "\n",
    "    for participant in participants:\n",
    "        df_fixation_participant = df_fixation[(df_fixation[\"Algorithm\"] == snippet) & (df_fixation[\"Participant\"] == participant)]\n",
    "        if len(df_fixation_participant) == 0:\n",
    "            continue\n",
    "        start_times = eval(df_fixation_participant[\"Fixation_startT\"].values[0])\n",
    "        end_times = eval(df_fixation_participant[\"Fixation_endT\"].values[0])\n",
    "        y_coordinates = eval(df_fixation_participant[\"Fixation_y\"].values[0])\n",
    "        y_range = eval(df_fixation_participant[\"Fixation_y_range\"].values[0])\n",
    "        idx_values = range(len(start_times))\n",
    "        for (fix_idx, start, end, y, y_range) in zip(idx_values, start_times, end_times, y_coordinates, y_range):\n",
    "            low_y = int(float(y) - math.ceil(float(y_range)))\n",
    "            high_y = int(float(y) + math.ceil(float(y_range)))\n",
    "            possible_coordinates = [y for y in range(low_y, high_y + 1)]\n",
    "\n",
    "            found = False\n",
    "            for idx, row in df_token_per_algo.iterrows():\n",
    "                line_number = row[\"Line\"]\n",
    "                bounding_box = row[\"BoundingBox\"]\n",
    "\n",
    "                for possible_y in possible_coordinates:\n",
    "                    if bounding_box[1] <= possible_y <= bounding_box[3]:\n",
    "                        df_line_fixation_per_participant.loc[len(df_line_fixation_per_participant)] = [snippet, participant, fix_idx, start, end, line_number]\n",
    "                        found = True\n",
    "                        break\n",
    "                if found:\n",
    "                    break\n",
    "\n",
    "df_line_fixation_per_participant"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "snippets = df_fixation[\"Algorithm\"].unique()\n",
    "df_snippet_length = pd.DataFrame(columns=[\"Algorithm\", \"LOC\"])\n",
    "for snippet in tqdm(snippets):\n",
    "    aoi_token_generator = f\"./../CodeSnippets/aois/Generators/{snippet}_ast.json\"\n",
    "    with open(aoi_token_generator) as f:\n",
    "        aoi_list = json.load(f)\n",
    "        data = aoi_list[\"source-code\"]\n",
    "        LOC = len(data)\n",
    "        df_snippet_length.loc[len(df_snippet_length)] = [snippet, LOC]\n",
    "df_snippet_length"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_behavioral = pd.read_csv('./data/filteredData/fixation_stats.csv', sep=\";\")\n",
    "df_behavioral = df_behavioral[df_behavioral[\"IsOutlier\"] == False]\n",
    "df_behavioral = df_behavioral[[\"Participant\", \"Algorithm\", \"Duration\", \"SkillScore\"]]\n",
    "df_behavioral"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_combined = pd.merge(df_line_fixation_per_participant, df_snippet_length, on=[\"Algorithm\"])\n",
    "df_combined = pd.merge(df_combined, df_behavioral, on=[\"Participant\", \"Algorithm\"])\n",
    "df_combined[\"FixationStart\"] = df_combined[\"FixationStart\"] / 1000.0\n",
    "df_combined[\"FixationEnd\"] = df_combined[\"FixationEnd\"] / 1000.0\n",
    "\n",
    "\n",
    "def loc_coverage_after_time_percentage(df, percentage):\n",
    "    end_duration = df[\"Duration\"].iloc[0]\n",
    "    loc = df[\"LOC\"].iloc[0]\n",
    "    max_duration = end_duration * percentage\n",
    "    df_filtered = df[df[\"FixationEnd\"] <= max_duration]\n",
    "    unique_loc = df_filtered[\"LineNumber\"].nunique()\n",
    "    return unique_loc / loc\n",
    "\n",
    "df_20 = df_combined.groupby([\"Algorithm\", \"Participant\"]).apply(lambda df : loc_coverage_after_time_percentage(df, 0.2))\n",
    "df_20 = df_20.reset_index()\n",
    "\n",
    "df_30 = df_combined.groupby([\"Algorithm\", \"Participant\"]).apply(lambda df : loc_coverage_after_time_percentage(df, 0.3))\n",
    "df_30 = df_30.reset_index()\n",
    "\n",
    "df_40 = df_combined.groupby([\"Algorithm\", \"Participant\"]).apply(lambda df : loc_coverage_after_time_percentage(df, 0.4))\n",
    "df_40 = df_40.reset_index()\n",
    "\n",
    "df_50 = df_combined.groupby([\"Algorithm\", \"Participant\"]).apply(lambda df : loc_coverage_after_time_percentage(df, 0.5))\n",
    "df_50 = df_50.reset_index()\n",
    "\n",
    "df_20 = df_20.groupby([\"Participant\"]).mean().values.reshape(37, )\n",
    "df_30 = df_30.groupby([\"Participant\"]).mean().values.reshape(37, )\n",
    "df_40 = df_40.groupby([\"Participant\"]).mean().values.reshape(37, )\n",
    "df_50 = df_50.groupby([\"Participant\"]).mean().values.reshape(37, )\n",
    "\n",
    "\n",
    "df_skill = df_behavioral[[\"Participant\", \"SkillScore\"]]\n",
    "df_skill = df_skill.drop_duplicates()\n",
    "\n",
    "df_code_coverage = pd.DataFrame({\"Participant\": participants, \"20%\": df_20, \"30%\": df_30, \"40%\": df_40, \"50%\": df_50})\n",
    "df_code_coverage.set_index(\"Participant\", inplace=True, drop=True)\n",
    "df_code_coverage = pd.merge(df_code_coverage, df_skill, on=[\"Participant\"])\n",
    "df_code_coverage.set_index(\"Participant\", inplace=True, drop=True)\n",
    "df_code_coverage"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_code_coverage[\"30%\"].mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# spearman correlation\n",
    "df_code_coverage.corr(method=\"spearman\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}